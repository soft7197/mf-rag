{
    "Math-68": {
        "function_num": 2,
        "functions": [
            {
                "path": "src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java",
                "start_loc": 160,
                "end_loc": 171,
                "buggy_function": "    public LevenbergMarquardtOptimizer() {\n\n        // set up the superclass with a default  max cost evaluations setting\n        setMaxIterations(1000);\n\n        // default values for the tuning parameters\n        setInitialStepBoundFactor(100.0);\n        setCostRelativeTolerance(1.0e-10);\n        setParRelativeTolerance(1.0e-10);\n        setOrthoTolerance(1.0e-10);\n\n    }\n",
                "fixed_function": "    public LevenbergMarquardtOptimizer() {\n\n        // set up the superclass with a default  max cost evaluations setting\n        setMaxIterations(1000);\n\n        // default values for the tuning parameters\n        setConvergenceChecker(null);\n        setInitialStepBoundFactor(100.0);\n        setCostRelativeTolerance(1.0e-10);\n        setParRelativeTolerance(1.0e-10);\n        setOrthoTolerance(1.0e-10);\n\n    }\n",
                "comment": "    /**\n     * Build an optimizer for least squares problems.\n     * <p>The default values for the algorithm settings are:\n     *   <ul>\n     *    <li>{@link #setConvergenceChecker vectorial convergence checker}: null</li>\n     *    <li>{@link #setInitialStepBoundFactor initial step bound factor}: 100.0</li>\n     *    <li>{@link #setMaxIterations maximal iterations}: 1000</li>\n     *    <li>{@link #setCostRelativeTolerance cost relative tolerance}: 1.0e-10</li>\n     *    <li>{@link #setParRelativeTolerance parameters relative tolerance}: 1.0e-10</li>\n     *    <li>{@link #setOrthoTolerance orthogonality tolerance}: 1.0e-10</li>\n     *   </ul>\n     * </p>\n     * <p>These default values may be overridden after construction. If the {@link\n     * #setConvergenceChecker vectorial convergence checker} is set to a non-null value, it\n     * will be used instead of the {@link #setCostRelativeTolerance cost relative tolerance}\n     * and {@link #setParRelativeTolerance parameters relative tolerance} settings.\n     */\n",
                "normalized_body": [
                    "    public LevenbergMarquardtOptimizer() {\n\n        // set up the superclass with a default  max cost evaluations setting\n        setMaxIterations(1000);\n\n        // default values for the tuning parameters\n        setInitialStepBoundFactor(100.0);\n        setCostRelativeTolerance(1.0e-10);\n        setParRelativeTolerance(1.0e-10);\n        setOrthoTolerance(1.0e-10);\n\n    }\n"
                ],
                "isConstructor": true,
                "top_similar_methods": [
                    [
                        0.9744718074798584,
                        "@Override public StringBuffer format(final Object obj, final StringBuffer toAppendTo, final FieldPosition pos) { final StringBuffer ret; if (obj instanceof BigFraction) { ret = format((BigFraction) obj, toAppendTo, pos); } else if (obj instanceof BigInteger) { ret = format(new BigFraction((BigInteger) obj), toAppendTo, pos); } else if (obj instanceof Number) { ret = format(new BigFraction(((Number) obj).doubleValue()), toAppendTo, pos); } else { throw MathRuntimeException.createIllegalArgumentException(\\\"cannot format given object as a fraction number\\\"); } return ret; }"
                    ],
                    [
                        0.9743202924728394,
                        "public void testGetColumn() { FieldMatrix<Fraction> m = new Array2DRowFieldMatrix<Fraction>(subTestData); Fraction[] mColumn1 = columnToArray(subColumn1); Fraction[] mColumn3 = columnToArray(subColumn3); checkArrays(mColumn1, m.getColumn(1)); checkArrays(mColumn3, m.getColumn(3)); try { m.getColumn(-1); fail(\\\"Expecting MatrixIndexException\\\"); } catch (MatrixIndexException ex) { } try { m.getColumn(4); fail(\\\"Expecting MatrixIndexException\\\"); } catch (MatrixIndexException ex) { } }"
                    ],
                    [
                        0.9735205769538879,
                        "public void testSetColumnMatrix() { RealMatrix m = new RealMatrixImpl(subTestData); RealMatrix mColumn3 = new RealMatrixImpl(subColumn3); assertNotSame(mColumn3, m.getColumnMatrix(1)); m.setColumnMatrix(1, mColumn3); assertEquals(mColumn3, m.getColumnMatrix(1)); try { m.setColumnMatrix(-1, mColumn3); fail(\\\"Expecting MatrixIndexException\\\"); } catch (MatrixIndexException ex) { } try { m.setColumnMatrix(0, m); fail(\\\"Expecting InvalidMatrixException\\\"); } catch (InvalidMatrixException ex) { } }"
                    ],
                    [
                        0.9734947681427002,
                        "public void testPlusMinus() { Array2DRowFieldMatrix<Fraction> m = new Array2DRowFieldMatrix<Fraction>(testData); Array2DRowFieldMatrix<Fraction> m2 = new Array2DRowFieldMatrix<Fraction>(testDataInv); TestUtils.assertEquals(m.subtract(m2), m2.scalarMultiply(new Fraction(-1)).add(m)); try { m.subtract(new Array2DRowFieldMatrix<Fraction>(testData2)); fail(\\\"Expecting illegalArgumentException\\\"); } catch (IllegalArgumentException ex) { } }"
                    ],
                    [
                        0.9731267690658569,
                        "public static <T extends FieldElement<T>> FieldMatrix<T> createFieldIdentityMatrix(final Field<T> field, final int dimension) { final T zero = field.getZero(); final T one = field.getOne(); @SuppressWarnings(\\\"unchecked\\\") final T[][] d = (T[][]) Array.newInstance(zero.getClass(), new int[] { dimension, dimension }); for (int row = 0; row < dimension; row++) { final T[] dRow = d[row]; Arrays.fill(dRow, zero); dRow[row] = one; } return new Array2DRowFieldMatrix<T>(d, false); }"
                    ],
                    [
                        0.9730576276779175,
                        "public void testGetColumn() { FieldMatrix<Fraction> m = new BlockFieldMatrix<Fraction>(subTestData); Fraction[] mColumn1 = columnToArray(subColumn1); Fraction[] mColumn3 = columnToArray(subColumn3); checkArrays(mColumn1, m.getColumn(1)); checkArrays(mColumn3, m.getColumn(3)); try { m.getColumn(-1); fail(\\\"Expecting MatrixIndexException\\\"); } catch (MatrixIndexException ex) { } try { m.getColumn(4); fail(\\\"Expecting MatrixIndexException\\\"); } catch (MatrixIndexException ex) { } }"
                    ],
                    [
                        0.9729646444320679,
                        "public void testSetColumnMatrix() { RealMatrix m = new BlockRealMatrix(subTestData); RealMatrix mColumn3 = new BlockRealMatrix(subColumn3); assertNotSame(mColumn3, m.getColumnMatrix(1)); m.setColumnMatrix(1, mColumn3); assertEquals(mColumn3, m.getColumnMatrix(1)); try { m.setColumnMatrix(-1, mColumn3); fail(\\\"Expecting MatrixIndexException\\\"); } catch (MatrixIndexException ex) { } try { m.setColumnMatrix(0, m); fail(\\\"Expecting InvalidMatrixException\\\"); } catch (InvalidMatrixException ex) { } }"
                    ]
                ],
                "non_directly_related_tests": [
                    "org.apache.commons.math.optimization.general.MinpackTest::testMinpackJennrichSampson",
                    "org.apache.commons.math.optimization.general.MinpackTest::testMinpackFreudensteinRoth"
                ],
                "generation": {
                    "1": {
                        "prompt": "You are an expert Java developer. Below are buggy method(s) from a large Java project. These methods cause one or more test failures.\nYour task is to fix the bugs in these methods. Use the provided test failure(s) to guide your reasoning.\n\n---\n\n## Buggy Methods\n\n\n```java\n    /**\n     * Build an optimizer for least squares problems.\n     * <p>The default values for the algorithm settings are:\n     *   <ul>\n     *    <li>{@link #setConvergenceChecker vectorial convergence checker}: null</li>\n     *    <li>{@link #setInitialStepBoundFactor initial step bound factor}: 100.0</li>\n     *    <li>{@link #setMaxIterations maximal iterations}: 1000</li>\n     *    <li>{@link #setCostRelativeTolerance cost relative tolerance}: 1.0e-10</li>\n     *    <li>{@link #setParRelativeTolerance parameters relative tolerance}: 1.0e-10</li>\n     *    <li>{@link #setOrthoTolerance orthogonality tolerance}: 1.0e-10</li>\n     *   </ul>\n     * </p>\n     * <p>These default values may be overridden after construction. If the {@link\n     * #setConvergenceChecker vectorial convergence checker} is set to a non-null value, it\n     * will be used instead of the {@link #setCostRelativeTolerance cost relative tolerance}\n     * and {@link #setParRelativeTolerance parameters relative tolerance} settings.\n     */\n\n    public LevenbergMarquardtOptimizer() {\n\n        // set up the superclass with a default  max cost evaluations setting\n        setMaxIterations(1000);\n\n        // default values for the tuning parameters\n        setInitialStepBoundFactor(100.0);\n        setCostRelativeTolerance(1.0e-10);\n        setParRelativeTolerance(1.0e-10);\n        setOrthoTolerance(1.0e-10);\n\n    }\n\n```\n\n```java\n    /** {@inheritDoc} */\n\n    @Override\n    protected VectorialPointValuePair doOptimize()\n        throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n\n        // arrays shared with the other private methods\n        solvedCols  = Math.min(rows, cols);\n        diagR       = new double[cols];\n        jacNorm     = new double[cols];\n        beta        = new double[cols];\n        permutation = new int[cols];\n        lmDir       = new double[cols];\n\n        // local point\n        double   delta   = 0;\n        double   xNorm   = 0;\n        double[] diag    = new double[cols];\n        double[] oldX    = new double[cols];\n        double[] oldRes  = new double[rows];\n        double[] work1   = new double[cols];\n        double[] work2   = new double[cols];\n        double[] work3   = new double[cols];\n\n        // evaluate the function at the starting point and calculate its norm\n        updateResidualsAndCost();\n\n        // outer loop\n        lmPar = 0;\n        boolean firstIteration = true;\n        while (true) {\n\n            incrementIterationsCounter();\n\n            // compute the Q.R. decomposition of the jacobian matrix\n            updateJacobian();\n            qrDecomposition();\n\n            // compute Qt.res\n            qTy(residuals);\n\n            // now we don't need Q anymore,\n            // so let jacobian contain the R matrix with its diagonal elements\n            for (int k = 0; k < solvedCols; ++k) {\n                int pk = permutation[k];\n                jacobian[k][pk] = diagR[pk];\n            }\n\n            if (firstIteration) {\n\n                // scale the point according to the norms of the columns\n                // of the initial jacobian\n                xNorm = 0;\n                for (int k = 0; k < cols; ++k) {\n                    double dk = jacNorm[k];\n                    if (dk == 0) {\n                        dk = 1.0;\n                    }\n                    double xk = dk * point[k];\n                    xNorm  += xk * xk;\n                    diag[k] = dk;\n                }\n                xNorm = Math.sqrt(xNorm);\n\n                // initialize the step bound delta\n                delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n\n            }\n\n            // check orthogonality between function vector and jacobian columns\n            double maxCosine = 0;\n            if (cost != 0) {\n                for (int j = 0; j < solvedCols; ++j) {\n                    int    pj = permutation[j];\n                    double s  = jacNorm[pj];\n                    if (s != 0) {\n                        double sum = 0;\n                        for (int i = 0; i <= j; ++i) {\n                            sum += jacobian[i][pj] * residuals[i];\n                        }\n                        maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n                    }\n                }\n            }\n            if (maxCosine <= orthoTolerance) {\n                // convergence has been reached\n                return new VectorialPointValuePair(point, objective);\n            }\n\n            // rescale if necessary\n            for (int j = 0; j < cols; ++j) {\n                diag[j] = Math.max(diag[j], jacNorm[j]);\n            }\n\n            // inner loop\n            for (double ratio = 0; ratio < 1.0e-4;) {\n\n                // save the state\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    oldX[pj] = point[pj];\n                }\n                double previousCost = cost;\n                double[] tmpVec = residuals;\n                residuals = oldRes;\n                oldRes    = tmpVec;\n\n                // determine the Levenberg-Marquardt parameter\n                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n\n                // compute the new point and the norm of the evolution direction\n                double lmNorm = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    lmDir[pj] = -lmDir[pj];\n                    point[pj] = oldX[pj] + lmDir[pj];\n                    double s = diag[pj] * lmDir[pj];\n                    lmNorm  += s * s;\n                }\n                lmNorm = Math.sqrt(lmNorm);\n\n                // on the first iteration, adjust the initial step bound.\n                if (firstIteration) {\n                    delta = Math.min(delta, lmNorm);\n                }\n\n                // evaluate the function at x + p and calculate its norm\n                updateResidualsAndCost();\n\n                // compute the scaled actual reduction\n                double actRed = -1.0;\n                if (0.1 * cost < previousCost) {\n                    double r = cost / previousCost;\n                    actRed = 1.0 - r * r;\n                }\n\n                // compute the scaled predicted reduction\n                // and the scaled directional derivative\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    double dirJ = lmDir[pj];\n                    work1[j] = 0;\n                    for (int i = 0; i <= j; ++i) {\n                        work1[i] += jacobian[i][pj] * dirJ;\n                    }\n                }\n                double coeff1 = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    coeff1 += work1[j] * work1[j];\n                }\n                double pc2 = previousCost * previousCost;\n                coeff1 = coeff1 / pc2;\n                double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n                double preRed = coeff1 + 2 * coeff2;\n                double dirDer = -(coeff1 + coeff2);\n\n                // ratio of the actual to the predicted reduction\n                ratio = (preRed == 0) ? 0 : (actRed / preRed);\n\n                // update the step bound\n                if (ratio <= 0.25) {\n                    double tmp =\n                        (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n                        if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {\n                            tmp = 0.1;\n                        }\n                        delta = tmp * Math.min(delta, 10.0 * lmNorm);\n                        lmPar /= tmp;\n                } else if ((lmPar == 0) || (ratio >= 0.75)) {\n                    delta = 2 * lmNorm;\n                    lmPar *= 0.5;\n                }\n\n                // test for successful iteration.\n                if (ratio >= 1.0e-4) {\n                    // successful iteration, update the norm\n                    firstIteration = false;\n                    xNorm = 0;\n                    for (int k = 0; k < cols; ++k) {\n                        double xK = diag[k] * point[k];\n                        xNorm    += xK * xK;\n                    }\n                    xNorm = Math.sqrt(xNorm);\n                } else {\n                    // failed iteration, reset the previous values\n                    cost = previousCost;\n                    for (int j = 0; j < solvedCols; ++j) {\n                        int pj = permutation[j];\n                        point[pj] = oldX[pj];\n                    }\n                    tmpVec    = residuals;\n                    residuals = oldRes;\n                    oldRes    = tmpVec;\n                }\n\n                // tests for convergence.\n                    // we use the vectorial convergence checker\n                    // we use the Levenberg-Marquardt specific convergence parameters\n                    if (((Math.abs(actRed) <= costRelativeTolerance) &&\n                         (preRed <= costRelativeTolerance) &&\n                         (ratio <= 2.0)) ||\n                        (delta <= parRelativeTolerance * xNorm)) {\n                        return new VectorialPointValuePair(point, objective);\n                    }\n\n                // tests for termination and stringent tolerances\n                // (2.2204e-16 is the machine epsilon for IEEE754)\n                if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n                    throw new OptimizationException(\"cost relative tolerance is too small ({0}),\" +\n                            \" no further reduction in the\" +\n                            \" sum of squares is possible\",\n                            costRelativeTolerance);\n                } else if (delta <= 2.2204e-16 * xNorm) {\n                    throw new OptimizationException(\"parameters relative tolerance is too small\" +\n                            \" ({0}), no further improvement in\" +\n                            \" the approximate solution is possible\",\n                            parRelativeTolerance);\n                } else if (maxCosine <= 2.2204e-16)  {\n                    throw new OptimizationException(\"orthogonality tolerance is too small ({0}),\" +\n                            \" solution is orthogonal to the jacobian\",\n                            orthoTolerance);\n                }\n\n            }\n\n        }\n\n    }\n\n```\n\n---\n\n## Failing Test Case(s)\n\n \n#Test method 1:\n```java\n  public void testMinpackJennrichSampson() {\n    minpackTest(new JennrichSampsonFunction(10, new double[] { 0.3, 0.4 },\n                                            64.5856498144943, 11.1517793413499,\n                                            new double[] {\n                                             0.2578330049, 0.257829976764542\n                                            }), false);\n  }\n```\n#Error message from the test method 1: junit.framework.AssertionFailedError: expected:<0.2578330049> but was:<0.257819926636807>\n \n#Test method 2:\n```java\n  public void testMinpackFreudensteinRoth() {\n    minpackTest(new FreudensteinRothFunction(new double[] { 0.5, -2.0 },\n                                             20.0124960961895, 6.99887517584575,\n                                             new double[] {\n                                               11.4124844654993,\n                                               -0.896827913731509\n                                             }), false);\n    minpackTest(new FreudensteinRothFunction(new double[] { 5.0, -20.0 },\n                                             12432.833948863, 6.9988751744895,\n                                             new double[] {\n                                               11.4121122022341,\n                                               -0.8968550851268697\n                                             }), false);\n    minpackTest(new FreudensteinRothFunction(new double[] { 50.0, -200.0 },\n                                             11426454.595762, 6.99887517242903,\n                                             new double[] {\n                                               11.412069435091231,\n                                               -0.8968582807605691\n                                             }), false);\n  }\n```\n#Error message from the test method 2: junit.framework.AssertionFailedError: expected:<11.4121122022341> but was:<11.41300466147456>\n\n---\n\n## Your Goal\n\nFix the buggy methods. Return only the fixed Java methods. Do not include explanations or other text.\n",
                        "patches": [
                            "\n    public LevenbergMarquardtOptimizer() {\n\n        // set up the superclass with a default  max cost evaluations setting\n        setMaxIterations(1000);\n\n        // default values for the tuning parameters\n        setInitialStepBoundFactor(100.0);\n        setCostRelativeTolerance(1.0e-10);\n        setParRelativeTolerance(1.0e-10);\n        setOrthoTolerance(1.0e-10);\n\n        // Make sure to initialize any optional fields or required parameters\n        setConvergenceChecker(null);\n\n    }\n",
                            "\n    /**\n     * Build an optimizer for least squares problems.\n     * <p>The default values for the algorithm settings are:\n     *   <ul>\n     *    <li>{@link #setConvergenceChecker vectorial convergence checker}: null</li>\n     *    <li>{@link #setInitialStepBoundFactor initial step bound factor}: 100.0</li>\n     *    <li>{@link #setMaxIterations maximal iterations}: 1000</li>\n     *    <li>{@link #setCostRelativeTolerance cost relative tolerance}: 1.0e-10</li>\n     *    <li>{@link #setParRelativeTolerance parameters relative tolerance}: 1.0e-10</li>\n     *    <li>{@link #setOrthoTolerance orthogonality tolerance}: 1.0e-10</li>\n     *   </ul>\n     * </p>\n     * <p>These default values may be overridden after construction. If the {@link\n     * #setConvergenceChecker vectorial convergence checker} is set to a non-null value, it\n     * will be used instead of the {@link #setCostRelativeTolerance cost relative tolerance}\n     * and {@link #setParRelativeTolerance parameters relative tolerance} settings.\n     */\n\n    public LevenbergMarquardtOptimizer() {\n\n        // set up the superclass with a default  max cost evaluations setting\n        setMaxIterations(1000);\n\n        // default values for the tuning parameters\n        setInitialStepBoundFactor(100.0);\n        setCostRelativeTolerance(1.0e-10);\n        setParRelativeTolerance(1.0e-10);\n        setOrthoTolerance(1.0e-10);\n\n    }\n\n    /** {@inheritDoc} */\n\n    @Override\n    protected VectorialPointValuePair doOptimize()\n        throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n\n        // arrays shared with the other private methods\n        solvedCols  = Math.min(rows, cols);\n        diagR       = new double[cols];\n        jacNorm     = new double[cols];\n        beta        = new double[cols];\n        permutation = new int[cols];\n        lmDir       = new double[cols];\n\n        // local point\n        double   delta   = 0;\n        double   xNorm   = 0;\n        double[] diag    = new double[cols];\n        double[] oldX    = new double[cols];\n        double[] oldRes  = new double[rows];\n        double[] work1   = new double[cols];\n        double[] work2   = new double[cols];\n        double[] work3   = new double[cols];\n\n        // evaluate the function at the starting point and calculate its norm\n        updateResidualsAndCost();\n\n        // outer loop\n        lmPar = 0;\n        boolean firstIteration = true;\n        while (true) {\n\n            incrementIterationsCounter();\n\n            // compute the Q.R. decomposition of the jacobian matrix\n            updateJacobian();\n            qrDecomposition();\n\n            // compute Qt.res\n            qTy(residuals);\n\n            // now we don't need Q anymore,\n            // so let jacobian contain the R matrix with its diagonal elements\n            for (int k = 0; k < solvedCols; ++k) {\n                int pk = permutation[k];\n                jacobian[k][pk] = diagR[pk];\n            }\n\n            if (firstIteration) {\n\n                // scale the point according to the norms of the columns\n                // of the initial jacobian\n                xNorm = 0;\n                for (int k = 0; k < cols; ++k) {\n                    double dk = jacNorm[k];\n                    if (dk == 0) {\n                        dk = 1.0;\n                    }\n                    double xk = dk * Math.abs(point[k]); // Calculation of xk was incorrect\n                    xNorm  += xk * xk;\n                    diag[k] = dk;\n                }\n                xNorm = Math.sqrt(xNorm);\n\n                // initialize the step bound delta\n                delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n\n            }\n\n            // check orthogonality between function vector and jacobian columns\n            double maxCosine = 0;\n            if (cost != 0) {\n                for (int j = 0; j < solvedCols; ++j) {\n                    int    pj = permutation[j];\n                    double s  = jacNorm[pj];\n                    if (s != 0) {\n                        double sum = 0;\n                        for (int i = 0; i <= j; ++i) {\n                            sum += jacobian[i][pj] * residuals[i];\n                        }\n                        maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n                    }\n                }\n            }\n            if (maxCosine <= orthoTolerance) {\n                // convergence has been reached\n                return new VectorialPointValuePair(point, objective);\n            }\n\n            // rescale if necessary\n            for (int j = 0; j < cols; ++j) {\n                diag[j] = Math.max(diag[j], jacNorm[j]);\n            }\n\n            // inner loop\n            for (double ratio = 0; ratio < 1.0e-4;) {\n\n                // save the state\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    oldX[pj] = point[pj];\n                }\n                double previousCost = cost;\n                double[] tmpVec = residuals;\n                residuals = oldRes;\n                oldRes    = tmpVec;\n\n                // determine the Levenberg-Marquardt parameter\n                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n\n                // compute the new point and the norm of the evolution direction\n                double lmNorm = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    lmDir[pj] = -lmDir[pj];\n                    point[pj] = oldX[pj] + lmDir[pj];\n                    double s = diag[pj] * lmDir[pj];\n                    lmNorm  += s * s;\n                }\n                lmNorm = Math.sqrt(lmNorm);\n\n                // on the first iteration, adjust the initial step bound.\n                if (firstIteration) {\n                    delta = Math.min(delta, lmNorm);\n                }\n\n                // evaluate the function at x + p and calculate its norm\n                updateResidualsAndCost();\n\n                // compute the scaled actual reduction\n                double actRed = -1.0;\n                if (0.1 * cost < previousCost) {\n                    double r = cost / previousCost;\n                    actRed = 1.0 - r * r;\n                }\n\n                // compute the scaled predicted reduction\n                // and the scaled directional derivative\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    double dirJ = lmDir[pj]; // Determining direction needed correction\n                    work1[j] = 0;\n                    for (int i = 0; i <= j; ++i) {\n                        work1[i] += jacobian[i][pj] * dirJ;\n                    }\n                }\n                double coeff1 = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    coeff1 += work1[j] * work1[j];\n                }\n                double pc2 = previousCost * previousCost;\n                coeff1 = coeff1 / pc2;\n                double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n                double preRed = coeff1 + 2 * coeff2;\n                double dirDer = -(coeff1 + coeff2);\n\n                // ratio of the actual to the predicted reduction\n                ratio = (preRed == 0) ? 0 : (actRed / preRed);\n\n                // update the step bound\n                if (ratio <= 0.25) {\n                    double tmp =\n                        (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n                        if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {\n                            tmp = 0.1;\n                        }\n                        delta = tmp * Math.min(delta, 10.0 * lmNorm);\n                        lmPar /= tmp;\n                } else if ((lmPar == 0) || (ratio >= 0.75)) {\n                    delta = 2 * lmNorm;\n                    lmPar *= 0.5;\n                }\n\n                // test for successful iteration.\n                if (ratio >= 1.0e-4) {\n                    // successful iteration, update the norm\n                    firstIteration = false;\n                    xNorm = 0;\n                    for (int k = 0; k < cols; ++k) {\n                        double xK = diag[k] * point[k];\n                        xNorm    += xK * xK;\n                    }\n                    xNorm = Math.sqrt(xNorm);\n                } else {\n                    // failed iteration, reset the previous values\n                    cost = previousCost;\n                    for (int j = 0; j < solvedCols; ++j) {\n                        int pj = permutation[j];\n                        point[pj] = oldX[pj];\n                    }\n                    tmpVec    = residuals;\n                    residuals = oldRes;\n                    oldRes    = tmpVec;\n                }\n\n                // tests for convergence.\n                    // we use the vectorial convergence checker\n                    // we use the Levenberg-Marquardt specific convergence parameters\n                    if (((Math.abs(actRed) <= costRelativeTolerance) &&\n                         (preRed <= costRelativeTolerance) &&\n                         (ratio <= 2.0)) ||\n                        (delta <= parRelativeTolerance * xNorm)) {\n                        return new VectorialPointValuePair(point, objective);\n                    }\n\n                // tests for termination and stringent tolerances\n                // (2.2204e-16 is the machine epsilon for IEEE754)\n                if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n                    throw new OptimizationException(\"cost relative tolerance is too small ({0}),\" +\n                            \" no further reduction in the\" +\n                            \" sum of squares is possible\",\n                            costRelativeTolerance);\n                } else if (delta <= 2.2204e-16 * xNorm) {\n                    throw new OptimizationException(\"parameters relative tolerance is too small\" +\n                            \" ({0}), no further improvement in\" +\n                            \" the approximate solution is possible\",\n                            parRelativeTolerance);\n                } else if (maxCosine <= 2.2204e-16)  {\n                    throw new OptimizationException(\"orthogonality tolerance is too small ({0}),\" +\n                            \" solution is orthogonal to the jacobian\",\n                            orthoTolerance);\n                }\n\n            }\n\n        }\n\n    }\n",
                            "\n    /**\n     * Build an optimizer for least squares problems.\n     * <p>The default values for the algorithm settings are:\n     *   <ul>\n     *    <li>{@link #setConvergenceChecker vectorial convergence checker}: null</li>\n     *    <li>{@link #setInitialStepBoundFactor initial step bound factor}: 100.0</li>\n     *    <li>{@link #setMaxIterations maximal iterations}: 1000</li>\n     *    <li>{@link #setCostRelativeTolerance cost relative tolerance}: 1.0e-10</li>\n     *    <li>{@link #setParRelativeTolerance parameters relative tolerance}: 1.0e-10</li>\n     *    <li>{@link #setOrthoTolerance orthogonality tolerance}: 1.0e-10</li>\n     *   </ul>\n     * </p>\n     * <p>These default values may be overridden after construction. If the {@link\n     * #setConvergenceChecker vectorial convergence checker} is set to a non-null value, it\n     * will be used instead of the {@link #setCostRelativeTolerance cost relative tolerance}\n     * and {@link #setParRelativeTolerance parameters relative tolerance} settings.\n     */\n\n    public LevenbergMarquardtOptimizer() {\n        super(null);\n        // set up the superclass with a default  max cost evaluations setting\n        setMaxIterations(1000);\n\n        // default values for the tuning parameters\n        setInitialStepBoundFactor(100.0);\n        setCostRelativeTolerance(1.0e-10);\n        setParRelativeTolerance(1.0e-10);\n        setOrthoTolerance(1.0e-10);\n    }\n",
                            "\n    /**\n     * Build an optimizer for least squares problems.\n     * <p>The default values for the algorithm settings are:\n     *   <ul>\n     *    <li>{@link #setConvergenceChecker vectorial convergence checker}: null</li>\n     *    <li>{@link #setInitialStepBoundFactor initial step bound factor}: 100.0</li>\n     *    <li>{@link #setMaxIterations maximal iterations}: 1000</li>\n     *    <li>{@link #setCostRelativeTolerance cost relative tolerance}: 1.0e-10</li>\n     *    <li>{@link #setParRelativeTolerance parameters relative tolerance}: 1.0e-10</li>\n     *    <li>{@link #setOrthoTolerance orthogonality tolerance}: 1.0e-10</li>\n     *   </ul>\n     * </p>\n     * <p>These default values may be overridden after construction. If the {@link\n     * #setConvergenceChecker vectorial convergence checker} is set to a non-null value, it\n     * will be used instead of the {@link #setCostRelativeTolerance cost relative tolerance}\n     * and {@link #setParRelativeTolerance parameters relative tolerance} settings.\n     */\n\n    public LevenbergMarquardtOptimizer() {\n\n        // set up the superclass with a default  max cost evaluations setting\n        setMaxIterations(1000);\n\n        // default values for the tuning parameters\n        setInitialStepBoundFactor(100.0);\n        setCostRelativeTolerance(1.0e-10);\n        setParRelativeTolerance(1.0e-10);\n        setOrthoTolerance(1.0e-10);\n\n    }\n\n",
                            "\n    /**\n     * Build an optimizer for least squares problems.\n     * <p>The default values for the algorithm settings are:\n     *   <ul>\n     *    <li>{@link #setConvergenceChecker vectorial convergence checker}: null</li>\n     *    <li>{@link #setInitialStepBoundFactor initial step bound factor}: 100.0</li>\n     *    <li>{@link #setMaxIterations maximal iterations}: 1000</li>\n     *    <li>{@link #setCostRelativeTolerance cost relative tolerance}: 1.0e-12</li>\n     *    <li>{@link #setParRelativeTolerance parameters relative tolerance}: 1.0e-12</li>\n     *    <li>{@link #setOrthoTolerance orthogonality tolerance}: 1.0e-12</li>\n     *   </ul>\n     * </p>\n     * <p>These default values may be overridden after construction. If the {@link\n     * #setConvergenceChecker vectorial convergence checker} is set to a non-null value, it\n     * will be used instead of the {@link #setCostRelativeTolerance cost relative tolerance}\n     * and {@link #setParRelativeTolerance parameters relative tolerance} settings.\n     */\n\n    public LevenbergMarquardtOptimizer() {\n\n        // set up the superclass with a default  max cost evaluations setting\n        setMaxIterations(1000);\n\n        // default values for the tuning parameters\n        setInitialStepBoundFactor(100.0);\n        setCostRelativeTolerance(1.0e-12);\n        setParRelativeTolerance(1.0e-12);\n        setOrthoTolerance(1.0e-12);\n\n    }\n\n",
                            "\n    public LevenbergMarquardtOptimizer() {\n\n        // set up the superclass with a default max cost evaluations setting\n        setMaxIterations(1000);\n\n        // default values for the tuning parameters\n        setInitialStepBoundFactor(100.0);\n        setCostRelativeTolerance(1.0e-10);\n        setParRelativeTolerance(1.0e-10);\n        setOrthoTolerance(1.0e-10);\n\n        convergenceChecker = null;\n    }\n",
                            "\n    /**\n     * Build an optimizer for least squares problems.\n     * <p>The default values for the algorithm settings are:\n     *   <ul>\n     *    <li>{@link #setConvergenceChecker vectorial convergence checker}: null</li>\n     *    <li>{@link #setInitialStepBoundFactor initial step bound factor}: 100.0</li>\n     *    <li>{@link #setMaxIterations maximal iterations}: 1000</li>\n     *    <li>{@link #setCostRelativeTolerance cost relative tolerance}: 1.0e-10</li>\n     *    <li>{@link #setParRelativeTolerance parameters relative tolerance}: 1.0e-10</li>\n     *    <li>{@link #setOrthoTolerance orthogonality tolerance}: 1.0e-10</li>\n     *   </ul>\n     * </p>\n     * <p>These default values may be overridden after construction. If the {@link\n     * #setConvergenceChecker vectorial convergence checker} is set to a non-null value, it\n     * will be used instead of the {@link #setCostRelativeTolerance cost relative tolerance}\n     * and {@link #setParRelativeTolerance parameters relative tolerance} settings.\n     */\n\n    public LevenbergMarquardtOptimizer() {\n\n        // set up the superclass with a default  max cost evaluations setting\n        setMaxIterations(1000);\n\n        // default values for the tuning parameters\n        setInitialStepBoundFactor(100.0);\n        setCostRelativeTolerance(1.0e-10);\n        setParRelativeTolerance(1.0e-10);\n        setOrthoTolerance(1.0e-10);\n\n    }\n",
                            "\npublic LevenbergMarquardtOptimizer() {\n\n    // set up the superclass with a default max cost evaluations setting\n    setMaxIterations(1000);\n\n    // default values for the tuning parameters\n    setInitialStepBoundFactor(100.0);\n    setCostRelativeTolerance(1.0e-10);\n    setParRelativeTolerance(1.0e-10);\n    setOrthoTolerance(1.0e-10);\n    setConvergenceChecker(null); // Added to explicitly set the convergence checker to null\n}\n",
                            "\n    public LevenbergMarquardtOptimizer() {\n\n        // set up the superclass with a default  max cost evaluations setting\n        setMaxIterations(1000);\n\n        // default values for the tuning parameters\n        setInitialStepBoundFactor(100.0);\n        setCostRelativeTolerance(1.0e-10);\n        setParRelativeTolerance(1.0e-10);\n        setOrthoTolerance(1.0e-10);\n\n        setConvergenceChecker(null);\n\n    }\n\n    @Override\n    protected VectorialPointValuePair doOptimize()\n        throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n\n        solvedCols  = Math.min(rows, cols);\n        diagR       = new double[cols];\n        jacNorm     = new double[cols];\n        beta        = new double[cols];\n        permutation = new int[cols];\n        lmDir       = new double[cols];\n\n        double   delta   = 0;\n        double   xNorm   = 0;\n        double[] diag    = new double[cols];\n        double[] oldX    = new double[cols];\n        double[] oldRes  = new double[rows];\n        double[] work1   = new double[cols];\n        double[] work2   = new double[cols];\n        double[] work3   = new double[cols];\n\n        updateResidualsAndCost();\n\n        lmPar = 0;\n        boolean firstIteration = true;\n        while (true) {\n            incrementIterationsCounter();\n\n            updateJacobian();\n            qrDecomposition();\n\n            qTy(residuals);\n\n            for (int k = 0; k < solvedCols; ++k) {\n                int pk = permutation[k];\n                jacobian[k][pk] = diagR[pk];\n            }\n\n            if (firstIteration) {\n                xNorm = 0;\n                for (int k = 0; k < cols; ++k) {\n                    double dk = jacNorm[k];\n                    if (dk == 0) {\n                        dk = 1.0;\n                    }\n                    double xk = dk * point[k];\n                    xNorm  += xk * xk;\n                    diag[k] = dk;\n                }\n                xNorm = Math.sqrt(xNorm);\n                delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n            }\n\n            double maxCosine = 0;\n            if (cost != 0) {\n                for (int j = 0; j < solvedCols; ++j) {\n                    int    pj = permutation[j];\n                    double s  = jacNorm[pj];\n                    if (s != 0) {\n                        double sum = 0;\n                        for (int i = 0; i <= j; ++i) {\n                            sum += jacobian[i][pj] * residuals[i];\n                        }\n                        maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n                    }\n                }\n            }\n            if (maxCosine <= orthoTolerance) {\n                return new VectorialPointValuePair(point, objective);\n            }\n\n            for (int j = 0; j < cols; ++j) {\n                diag[j] = Math.max(diag[j], jacNorm[j]);\n            }\n\n            for (double ratio = 0; ratio < 1.0e-4;) {\n\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    oldX[pj] = point[pj];\n                }\n                double previousCost = cost;\n                double[] tmpVec = residuals;\n                residuals = oldRes;\n                oldRes    = tmpVec;\n\n                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n\n                double lmNorm = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    lmDir[pj] = -lmDir[pj];\n                    point[pj] = oldX[pj] + lmDir[pj];\n                    double s = diag[pj] * lmDir[pj];\n                    lmNorm  += s * s;\n                }\n                lmNorm = Math.sqrt(lmNorm);\n\n                if (firstIteration) {\n                    delta = Math.min(delta, lmNorm);\n                }\n\n                updateResidualsAndCost();\n\n                double actRed = -1.0;\n                if (0.1 * cost < previousCost) {\n                    double r = cost / previousCost;\n                    actRed = 1.0 - r * r;\n                }\n\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    double dirJ = lmDir[pj];\n                    work1[j] = 0;\n                    for (int i = 0; i <= j; ++i) {\n                        work1[i] += jacobian[i][pj] * dirJ;\n                    }\n                }\n                double coeff1 = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    coeff1 += work1[j] * work1[j];\n                }\n                double pc2 = previousCost * previousCost;\n                coeff1 = coeff1 / pc2;\n                double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n                double preRed = coeff1 + 2 * coeff2;\n                double dirDer = -(coeff1 + coeff2);\n\n                ratio = (preRed == 0) ? 0 : (actRed / preRed);\n\n                if (ratio <= 0.25) {\n                    double tmp =\n                        (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n                        if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {\n                            tmp = 0.1;\n                        }\n                        delta = tmp * Math.min(delta, 10.0 * lmNorm);\n                        lmPar /= tmp;\n                } else if ((lmPar == 0) || (ratio >= 0.75)) {\n                    delta = 2 * lmNorm;\n                    lmPar *= 0.5;\n                }\n\n                if (ratio >= 1.0e-4) {\n                    firstIteration = false;\n                    xNorm = 0;\n                    for (int k = 0; k < cols; ++k) {\n                        double xK = diag[k] * point[k];\n                        xNorm    += xK * xK;\n                    }\n                    xNorm = Math.sqrt(xNorm);\n                } else {\n                    cost = previousCost;\n                    for (int j = 0; j < solvedCols; ++j) {\n                        int pj = permutation[j];\n                        point[pj] = oldX[pj];\n                    }\n                    tmpVec    = residuals;\n                    residuals = oldRes;\n                    oldRes    = tmpVec;\n                }\n\n                if (((Math.abs(actRed) <= costRelativeTolerance) &&\n                     (preRed <= costRelativeTolerance) &&\n                     (ratio <= 2.0)) ||\n                    (delta <= parRelativeTolerance * xNorm)) {\n                    return new VectorialPointValuePair(point, objective);\n                }\n\n                if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n                    throw new OptimizationException(\"cost relative tolerance is too small ({0}),\" +\n                            \" no further reduction in the\" +\n                            \" sum of squares is possible\",\n                            costRelativeTolerance);\n                } else if (delta <= 2.2204e-16 * xNorm) {\n                    throw new OptimizationException(\"parameters relative tolerance is too small\" +\n                            \" ({0}), no further improvement in\" +\n                            \" the approximate solution is possible\",\n                            parRelativeTolerance);\n                } else if (maxCosine <= 2.2204e-16)  {\n                    throw new OptimizationException(\"orthogonality tolerance is too small ({0}),\" +\n                            \" solution is orthogonal to the jacobian\",\n                            orthoTolerance);\n                }\n\n            }\n\n        }\n\n    }\n",
                            "\n    public LevenbergMarquardtOptimizer() {\n\n        // set up the superclass with a default max iterations setting\n        setMaxIterations(1000);\n\n        // default values for the tuning parameters\n        setInitialStepBoundFactor(100.0);\n        setCostRelativeTolerance(1.0e-10);\n        setParRelativeTolerance(1.0e-10);\n        setOrthoTolerance(1.0e-10);\n    }\n"
                        ]
                    }
                }
            },
            {
                "path": "src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java",
                "start_loc": 219,
                "end_loc": 444,
                "buggy_function": "    @Override\n    protected VectorialPointValuePair doOptimize()\n        throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n\n        // arrays shared with the other private methods\n        solvedCols  = Math.min(rows, cols);\n        diagR       = new double[cols];\n        jacNorm     = new double[cols];\n        beta        = new double[cols];\n        permutation = new int[cols];\n        lmDir       = new double[cols];\n\n        // local point\n        double   delta   = 0;\n        double   xNorm   = 0;\n        double[] diag    = new double[cols];\n        double[] oldX    = new double[cols];\n        double[] oldRes  = new double[rows];\n        double[] work1   = new double[cols];\n        double[] work2   = new double[cols];\n        double[] work3   = new double[cols];\n\n        // evaluate the function at the starting point and calculate its norm\n        updateResidualsAndCost();\n\n        // outer loop\n        lmPar = 0;\n        boolean firstIteration = true;\n        while (true) {\n\n            incrementIterationsCounter();\n\n            // compute the Q.R. decomposition of the jacobian matrix\n            updateJacobian();\n            qrDecomposition();\n\n            // compute Qt.res\n            qTy(residuals);\n\n            // now we don't need Q anymore,\n            // so let jacobian contain the R matrix with its diagonal elements\n            for (int k = 0; k < solvedCols; ++k) {\n                int pk = permutation[k];\n                jacobian[k][pk] = diagR[pk];\n            }\n\n            if (firstIteration) {\n\n                // scale the point according to the norms of the columns\n                // of the initial jacobian\n                xNorm = 0;\n                for (int k = 0; k < cols; ++k) {\n                    double dk = jacNorm[k];\n                    if (dk == 0) {\n                        dk = 1.0;\n                    }\n                    double xk = dk * point[k];\n                    xNorm  += xk * xk;\n                    diag[k] = dk;\n                }\n                xNorm = Math.sqrt(xNorm);\n\n                // initialize the step bound delta\n                delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n\n            }\n\n            // check orthogonality between function vector and jacobian columns\n            double maxCosine = 0;\n            if (cost != 0) {\n                for (int j = 0; j < solvedCols; ++j) {\n                    int    pj = permutation[j];\n                    double s  = jacNorm[pj];\n                    if (s != 0) {\n                        double sum = 0;\n                        for (int i = 0; i <= j; ++i) {\n                            sum += jacobian[i][pj] * residuals[i];\n                        }\n                        maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n                    }\n                }\n            }\n            if (maxCosine <= orthoTolerance) {\n                // convergence has been reached\n                return new VectorialPointValuePair(point, objective);\n            }\n\n            // rescale if necessary\n            for (int j = 0; j < cols; ++j) {\n                diag[j] = Math.max(diag[j], jacNorm[j]);\n            }\n\n            // inner loop\n            for (double ratio = 0; ratio < 1.0e-4;) {\n\n                // save the state\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    oldX[pj] = point[pj];\n                }\n                double previousCost = cost;\n                double[] tmpVec = residuals;\n                residuals = oldRes;\n                oldRes    = tmpVec;\n\n                // determine the Levenberg-Marquardt parameter\n                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n\n                // compute the new point and the norm of the evolution direction\n                double lmNorm = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    lmDir[pj] = -lmDir[pj];\n                    point[pj] = oldX[pj] + lmDir[pj];\n                    double s = diag[pj] * lmDir[pj];\n                    lmNorm  += s * s;\n                }\n                lmNorm = Math.sqrt(lmNorm);\n\n                // on the first iteration, adjust the initial step bound.\n                if (firstIteration) {\n                    delta = Math.min(delta, lmNorm);\n                }\n\n                // evaluate the function at x + p and calculate its norm\n                updateResidualsAndCost();\n\n                // compute the scaled actual reduction\n                double actRed = -1.0;\n                if (0.1 * cost < previousCost) {\n                    double r = cost / previousCost;\n                    actRed = 1.0 - r * r;\n                }\n\n                // compute the scaled predicted reduction\n                // and the scaled directional derivative\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    double dirJ = lmDir[pj];\n                    work1[j] = 0;\n                    for (int i = 0; i <= j; ++i) {\n                        work1[i] += jacobian[i][pj] * dirJ;\n                    }\n                }\n                double coeff1 = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    coeff1 += work1[j] * work1[j];\n                }\n                double pc2 = previousCost * previousCost;\n                coeff1 = coeff1 / pc2;\n                double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n                double preRed = coeff1 + 2 * coeff2;\n                double dirDer = -(coeff1 + coeff2);\n\n                // ratio of the actual to the predicted reduction\n                ratio = (preRed == 0) ? 0 : (actRed / preRed);\n\n                // update the step bound\n                if (ratio <= 0.25) {\n                    double tmp =\n                        (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n                        if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {\n                            tmp = 0.1;\n                        }\n                        delta = tmp * Math.min(delta, 10.0 * lmNorm);\n                        lmPar /= tmp;\n                } else if ((lmPar == 0) || (ratio >= 0.75)) {\n                    delta = 2 * lmNorm;\n                    lmPar *= 0.5;\n                }\n\n                // test for successful iteration.\n                if (ratio >= 1.0e-4) {\n                    // successful iteration, update the norm\n                    firstIteration = false;\n                    xNorm = 0;\n                    for (int k = 0; k < cols; ++k) {\n                        double xK = diag[k] * point[k];\n                        xNorm    += xK * xK;\n                    }\n                    xNorm = Math.sqrt(xNorm);\n                } else {\n                    // failed iteration, reset the previous values\n                    cost = previousCost;\n                    for (int j = 0; j < solvedCols; ++j) {\n                        int pj = permutation[j];\n                        point[pj] = oldX[pj];\n                    }\n                    tmpVec    = residuals;\n                    residuals = oldRes;\n                    oldRes    = tmpVec;\n                }\n\n                // tests for convergence.\n                    // we use the vectorial convergence checker\n                    // we use the Levenberg-Marquardt specific convergence parameters\n                    if (((Math.abs(actRed) <= costRelativeTolerance) &&\n                         (preRed <= costRelativeTolerance) &&\n                         (ratio <= 2.0)) ||\n                        (delta <= parRelativeTolerance * xNorm)) {\n                        return new VectorialPointValuePair(point, objective);\n                    }\n\n                // tests for termination and stringent tolerances\n                // (2.2204e-16 is the machine epsilon for IEEE754)\n                if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n                    throw new OptimizationException(\"cost relative tolerance is too small ({0}),\" +\n                            \" no further reduction in the\" +\n                            \" sum of squares is possible\",\n                            costRelativeTolerance);\n                } else if (delta <= 2.2204e-16 * xNorm) {\n                    throw new OptimizationException(\"parameters relative tolerance is too small\" +\n                            \" ({0}), no further improvement in\" +\n                            \" the approximate solution is possible\",\n                            parRelativeTolerance);\n                } else if (maxCosine <= 2.2204e-16)  {\n                    throw new OptimizationException(\"orthogonality tolerance is too small ({0}),\" +\n                            \" solution is orthogonal to the jacobian\",\n                            orthoTolerance);\n                }\n\n            }\n\n        }\n\n    }\n",
                "fixed_function": "    @Override\n    protected VectorialPointValuePair doOptimize()\n        throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n\n        // arrays shared with the other private methods\n        solvedCols  = Math.min(rows, cols);\n        diagR       = new double[cols];\n        jacNorm     = new double[cols];\n        beta        = new double[cols];\n        permutation = new int[cols];\n        lmDir       = new double[cols];\n\n        // local point\n        double   delta   = 0;\n        double   xNorm   = 0;\n        double[] diag    = new double[cols];\n        double[] oldX    = new double[cols];\n        double[] oldRes  = new double[rows];\n        double[] work1   = new double[cols];\n        double[] work2   = new double[cols];\n        double[] work3   = new double[cols];\n\n        // evaluate the function at the starting point and calculate its norm\n        updateResidualsAndCost();\n\n        // outer loop\n        lmPar = 0;\n        boolean firstIteration = true;\n        VectorialPointValuePair current = new VectorialPointValuePair(point, objective);\n        while (true) {\n\n            incrementIterationsCounter();\n\n            // compute the Q.R. decomposition of the jacobian matrix\n            VectorialPointValuePair previous = current;\n            updateJacobian();\n            qrDecomposition();\n\n            // compute Qt.res\n            qTy(residuals);\n\n            // now we don't need Q anymore,\n            // so let jacobian contain the R matrix with its diagonal elements\n            for (int k = 0; k < solvedCols; ++k) {\n                int pk = permutation[k];\n                jacobian[k][pk] = diagR[pk];\n            }\n\n            if (firstIteration) {\n\n                // scale the point according to the norms of the columns\n                // of the initial jacobian\n                xNorm = 0;\n                for (int k = 0; k < cols; ++k) {\n                    double dk = jacNorm[k];\n                    if (dk == 0) {\n                        dk = 1.0;\n                    }\n                    double xk = dk * point[k];\n                    xNorm  += xk * xk;\n                    diag[k] = dk;\n                }\n                xNorm = Math.sqrt(xNorm);\n\n                // initialize the step bound delta\n                delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n\n            }\n\n            // check orthogonality between function vector and jacobian columns\n            double maxCosine = 0;\n            if (cost != 0) {\n                for (int j = 0; j < solvedCols; ++j) {\n                    int    pj = permutation[j];\n                    double s  = jacNorm[pj];\n                    if (s != 0) {\n                        double sum = 0;\n                        for (int i = 0; i <= j; ++i) {\n                            sum += jacobian[i][pj] * residuals[i];\n                        }\n                        maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n                    }\n                }\n            }\n            if (maxCosine <= orthoTolerance) {\n                // convergence has been reached\n                return current;\n            }\n\n            // rescale if necessary\n            for (int j = 0; j < cols; ++j) {\n                diag[j] = Math.max(diag[j], jacNorm[j]);\n            }\n\n            // inner loop\n            for (double ratio = 0; ratio < 1.0e-4;) {\n\n                // save the state\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    oldX[pj] = point[pj];\n                }\n                double previousCost = cost;\n                double[] tmpVec = residuals;\n                residuals = oldRes;\n                oldRes    = tmpVec;\n\n                // determine the Levenberg-Marquardt parameter\n                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n\n                // compute the new point and the norm of the evolution direction\n                double lmNorm = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    lmDir[pj] = -lmDir[pj];\n                    point[pj] = oldX[pj] + lmDir[pj];\n                    double s = diag[pj] * lmDir[pj];\n                    lmNorm  += s * s;\n                }\n                lmNorm = Math.sqrt(lmNorm);\n\n                // on the first iteration, adjust the initial step bound.\n                if (firstIteration) {\n                    delta = Math.min(delta, lmNorm);\n                }\n\n                // evaluate the function at x + p and calculate its norm\n                updateResidualsAndCost();\n                current = new VectorialPointValuePair(point, objective);\n\n                // compute the scaled actual reduction\n                double actRed = -1.0;\n                if (0.1 * cost < previousCost) {\n                    double r = cost / previousCost;\n                    actRed = 1.0 - r * r;\n                }\n\n                // compute the scaled predicted reduction\n                // and the scaled directional derivative\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    double dirJ = lmDir[pj];\n                    work1[j] = 0;\n                    for (int i = 0; i <= j; ++i) {\n                        work1[i] += jacobian[i][pj] * dirJ;\n                    }\n                }\n                double coeff1 = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    coeff1 += work1[j] * work1[j];\n                }\n                double pc2 = previousCost * previousCost;\n                coeff1 = coeff1 / pc2;\n                double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n                double preRed = coeff1 + 2 * coeff2;\n                double dirDer = -(coeff1 + coeff2);\n\n                // ratio of the actual to the predicted reduction\n                ratio = (preRed == 0) ? 0 : (actRed / preRed);\n\n                // update the step bound\n                if (ratio <= 0.25) {\n                    double tmp =\n                        (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n                        if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {\n                            tmp = 0.1;\n                        }\n                        delta = tmp * Math.min(delta, 10.0 * lmNorm);\n                        lmPar /= tmp;\n                } else if ((lmPar == 0) || (ratio >= 0.75)) {\n                    delta = 2 * lmNorm;\n                    lmPar *= 0.5;\n                }\n\n                // test for successful iteration.\n                if (ratio >= 1.0e-4) {\n                    // successful iteration, update the norm\n                    firstIteration = false;\n                    xNorm = 0;\n                    for (int k = 0; k < cols; ++k) {\n                        double xK = diag[k] * point[k];\n                        xNorm    += xK * xK;\n                    }\n                    xNorm = Math.sqrt(xNorm);\n                } else {\n                    // failed iteration, reset the previous values\n                    cost = previousCost;\n                    for (int j = 0; j < solvedCols; ++j) {\n                        int pj = permutation[j];\n                        point[pj] = oldX[pj];\n                    }\n                    tmpVec    = residuals;\n                    residuals = oldRes;\n                    oldRes    = tmpVec;\n                }\n\n                // tests for convergence.\n                if (checker != null) {\n                    // we use the vectorial convergence checker\n                    if (checker.converged(getIterations(), previous, current)) {\n                        return current;                        \n                    }\n                } else {\n                    // we use the Levenberg-Marquardt specific convergence parameters\n                    if (((Math.abs(actRed) <= costRelativeTolerance) &&\n                         (preRed <= costRelativeTolerance) &&\n                         (ratio <= 2.0)) ||\n                        (delta <= parRelativeTolerance * xNorm)) {\n                        return current;\n                    }\n                }\n\n                // tests for termination and stringent tolerances\n                // (2.2204e-16 is the machine epsilon for IEEE754)\n                if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n                    throw new OptimizationException(\"cost relative tolerance is too small ({0}),\" +\n                            \" no further reduction in the\" +\n                            \" sum of squares is possible\",\n                            costRelativeTolerance);\n                } else if (delta <= 2.2204e-16 * xNorm) {\n                    throw new OptimizationException(\"parameters relative tolerance is too small\" +\n                            \" ({0}), no further improvement in\" +\n                            \" the approximate solution is possible\",\n                            parRelativeTolerance);\n                } else if (maxCosine <= 2.2204e-16)  {\n                    throw new OptimizationException(\"orthogonality tolerance is too small ({0}),\" +\n                            \" solution is orthogonal to the jacobian\",\n                            orthoTolerance);\n                }\n\n            }\n\n        }\n\n    }\n",
                "comment": "    /** {@inheritDoc} */\n",
                "normalized_body": [
                    "@Override protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException { solvedCols = Math.min(rows, cols); diagR = new double[cols]; jacNorm = new double[cols]; beta = new double[cols]; permutation = new int[cols]; lmDir = new double[cols]; double delta = 0; double xNorm = 0; double[] diag = new double[cols]; double[] oldX = new double[cols]; double[] oldRes = new double[rows]; double[] work1 = new double[cols]; double[] work2 = new double[cols]; double[] work3 = new double[cols]; updateResidualsAndCost(); lmPar = 0; boolean firstIteration = true; while (true) { incrementIterationsCounter(); updateJacobian(); qrDecomposition(); qTy(residuals); for (int k = 0; k < solvedCols; ++k) { int pk = permutation[k]; jacobian[k][pk] = diagR[pk]; } if (firstIteration) { xNorm = 0; for (int k = 0; k < cols; ++k) { double dk = jacNorm[k]; if (dk == 0) { dk = 1.0; } double xk = dk * point[k]; xNorm += xk * xk; diag[k] = dk; } xNorm = Math.sqrt(xNorm); delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm); } double maxCosine = 0; if (cost != 0) { for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; double s = jacNorm[pj]; if (s != 0) { double sum = 0; for (int i = 0; i <= j; ++i) { sum += jacobian[i][pj] * residuals[i]; } maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost)); } } } if (maxCosine <= orthoTolerance) { return new VectorialPointValuePair(point, objective); } for (int j = 0; j < cols; ++j) { diag[j] = Math.max(diag[j], jacNorm[j]); } for (double ratio = 0; ratio < 1.0e-4; ) { for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; oldX[pj] = point[pj]; } double previousCost = cost; double[] tmpVec = residuals; residuals = oldRes; oldRes = tmpVec; determineLMParameter(oldRes, delta, diag, work1, work2, work3); double lmNorm = 0; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; lmDir[pj] = -lmDir[pj]; point[pj] = oldX[pj] + lmDir[pj]; double s = diag[pj] * lmDir[pj]; lmNorm += s * s; } lmNorm = Math.sqrt(lmNorm); if (firstIteration) { delta = Math.min(delta, lmNorm); } updateResidualsAndCost(); double actRed = -1.0; if (0.1 * cost < previousCost) { double r = cost / previousCost; actRed = 1.0 - r * r; } for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; double dirJ = lmDir[pj]; work1[j] = 0; for (int i = 0; i <= j; ++i) { work1[i] += jacobian[i][pj] * dirJ; } } double coeff1 = 0; for (int j = 0; j < solvedCols; ++j) { coeff1 += work1[j] * work1[j]; } double pc2 = previousCost * previousCost; coeff1 = coeff1 / pc2; double coeff2 = lmPar * lmNorm * lmNorm / pc2; double preRed = coeff1 + 2 * coeff2; double dirDer = -(coeff1 + coeff2); ratio = (preRed == 0) ? 0 : (actRed / preRed); if (ratio <= 0.25) { double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5; if ((0.1 * cost >= previousCost) || (tmp < 0.1)) { tmp = 0.1; } delta = tmp * Math.min(delta, 10.0 * lmNorm); lmPar /= tmp; } else if ((lmPar == 0) || (ratio >= 0.75)) { delta = 2 * lmNorm; lmPar *= 0.5; } if (ratio >= 1.0e-4) { firstIteration = false; xNorm = 0; for (int k = 0; k < cols; ++k) { double xK = diag[k] * point[k]; xNorm += xK * xK; } xNorm = Math.sqrt(xNorm); } else { cost = previousCost; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; point[pj] = oldX[pj]; } tmpVec = residuals; residuals = oldRes; oldRes = tmpVec; } if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) { return new VectorialPointValuePair(point, objective); } if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) { throw new OptimizationException(\\\"cost relative tolerance is too small ({0}),\\\" + \\\" no further reduction in the\\\" + \\\" sum of squares is possible\\\", costRelativeTolerance); } else if (delta <= 2.2204e-16 * xNorm) { throw new OptimizationException(\\\"parameters relative tolerance is too small\\\" + \\\" ({0}), no further improvement in\\\" + \\\" the approximate solution is possible\\\", parRelativeTolerance); } else if (maxCosine <= 2.2204e-16) { throw new OptimizationException(\\\"orthogonality tolerance is too small ({0}),\\\" + \\\" solution is orthogonal to the jacobian\\\", orthoTolerance); } } } }"
                ],
                "top_similar_methods": [
                    [
                        1.0000000894069672,
                        "@Override protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException { solvedCols = Math.min(rows, cols); diagR = new double[cols]; jacNorm = new double[cols]; beta = new double[cols]; permutation = new int[cols]; lmDir = new double[cols]; double delta = 0; double xNorm = 0; double[] diag = new double[cols]; double[] oldX = new double[cols]; double[] oldRes = new double[rows]; double[] work1 = new double[cols]; double[] work2 = new double[cols]; double[] work3 = new double[cols]; updateResidualsAndCost(); lmPar = 0; boolean firstIteration = true; while (true) { incrementIterationsCounter(); updateJacobian(); qrDecomposition(); qTy(residuals); for (int k = 0; k < solvedCols; ++k) { int pk = permutation[k]; jacobian[k][pk] = diagR[pk]; } if (firstIteration) { xNorm = 0; for (int k = 0; k < cols; ++k) { double dk = jacNorm[k]; if (dk == 0) { dk = 1.0; } double xk = dk * point[k]; xNorm += xk * xk; diag[k] = dk; } xNorm = Math.sqrt(xNorm); delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm); } double maxCosine = 0; if (cost != 0) { for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; double s = jacNorm[pj]; if (s != 0) { double sum = 0; for (int i = 0; i <= j; ++i) { sum += jacobian[i][pj] * residuals[i]; } maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost)); } } } if (maxCosine <= orthoTolerance) { return new VectorialPointValuePair(point, objective); } for (int j = 0; j < cols; ++j) { diag[j] = Math.max(diag[j], jacNorm[j]); } for (double ratio = 0; ratio < 1.0e-4; ) { for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; oldX[pj] = point[pj]; } double previousCost = cost; double[] tmpVec = residuals; residuals = oldRes; oldRes = tmpVec; determineLMParameter(oldRes, delta, diag, work1, work2, work3); double lmNorm = 0; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; lmDir[pj] = -lmDir[pj]; point[pj] = oldX[pj] + lmDir[pj]; double s = diag[pj] * lmDir[pj]; lmNorm += s * s; } lmNorm = Math.sqrt(lmNorm); if (firstIteration) { delta = Math.min(delta, lmNorm); } updateResidualsAndCost(); double actRed = -1.0; if (0.1 * cost < previousCost) { double r = cost / previousCost; actRed = 1.0 - r * r; } for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; double dirJ = lmDir[pj]; work1[j] = 0; for (int i = 0; i <= j; ++i) { work1[i] += jacobian[i][pj] * dirJ; } } double coeff1 = 0; for (int j = 0; j < solvedCols; ++j) { coeff1 += work1[j] * work1[j]; } double pc2 = previousCost * previousCost; coeff1 = coeff1 / pc2; double coeff2 = lmPar * lmNorm * lmNorm / pc2; double preRed = coeff1 + 2 * coeff2; double dirDer = -(coeff1 + coeff2); ratio = (preRed == 0) ? 0 : (actRed / preRed); if (ratio <= 0.25) { double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5; if ((0.1 * cost >= previousCost) || (tmp < 0.1)) { tmp = 0.1; } delta = tmp * Math.min(delta, 10.0 * lmNorm); lmPar /= tmp; } else if ((lmPar == 0) || (ratio >= 0.75)) { delta = 2 * lmNorm; lmPar *= 0.5; } if (ratio >= 1.0e-4) { firstIteration = false; xNorm = 0; for (int k = 0; k < cols; ++k) { double xK = diag[k] * point[k]; xNorm += xK * xK; } xNorm = Math.sqrt(xNorm); } else { cost = previousCost; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; point[pj] = oldX[pj]; } tmpVec = residuals; residuals = oldRes; oldRes = tmpVec; } if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) { return new VectorialPointValuePair(point, objective); } if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) { throw new OptimizationException(\\\"cost relative tolerance is too small ({0}),\\\" + \\\" no further reduction in the\\\" + \\\" sum of squares is possible\\\", costRelativeTolerance); } else if (delta <= 2.2204e-16 * xNorm) { throw new OptimizationException(\\\"parameters relative tolerance is too small\\\" + \\\" ({0}), no further improvement in\\\" + \\\" the approximate solution is possible\\\", parRelativeTolerance); } else if (maxCosine <= 2.2204e-16) { throw new OptimizationException(\\\"orthogonality tolerance is too small ({0}),\\\" + \\\" solution is orthogonal to the jacobian\\\", orthoTolerance); } } } }"
                    ],
                    [
                        0.9976649135351181,
                        "@Override public void estimate(EstimationProblem problem) throws EstimationException { initializeEstimate(problem); solvedCols = Math.min(rows, cols); diagR = new double[cols]; jacNorm = new double[cols]; beta = new double[cols]; permutation = new int[cols]; lmDir = new double[cols]; double delta = 0; double xNorm = 0; double[] diag = new double[cols]; double[] oldX = new double[cols]; double[] oldRes = new double[rows]; double[] work1 = new double[cols]; double[] work2 = new double[cols]; double[] work3 = new double[cols]; updateResidualsAndCost(); lmPar = 0; boolean firstIteration = true; while (true) { updateJacobian(); qrDecomposition(); qTy(residuals); for (int k = 0; k < solvedCols; ++k) { int pk = permutation[k]; jacobian[k * cols + pk] = diagR[pk]; } if (firstIteration) { xNorm = 0; for (int k = 0; k < cols; ++k) { double dk = jacNorm[k]; if (dk == 0) { dk = 1.0; } double xk = dk * parameters[k].getEstimate(); xNorm += xk * xk; diag[k] = dk; } xNorm = Math.sqrt(xNorm); delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm); } double maxCosine = 0; if (cost != 0) { for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; double s = jacNorm[pj]; if (s != 0) { double sum = 0; int index = pj; for (int i = 0; i <= j; ++i) { sum += jacobian[index] * residuals[i]; index += cols; } maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost)); } } } if (maxCosine <= orthoTolerance) { return; } for (int j = 0; j < cols; ++j) { diag[j] = Math.max(diag[j], jacNorm[j]); } for (double ratio = 0; ratio < 1.0e-4; ) { for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; oldX[pj] = parameters[pj].getEstimate(); } double previousCost = cost; double[] tmpVec = residuals; residuals = oldRes; oldRes = tmpVec; determineLMParameter(oldRes, delta, diag, work1, work2, work3); double lmNorm = 0; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; lmDir[pj] = -lmDir[pj]; parameters[pj].setEstimate(oldX[pj] + lmDir[pj]); double s = diag[pj] * lmDir[pj]; lmNorm += s * s; } lmNorm = Math.sqrt(lmNorm); if (firstIteration) { delta = Math.min(delta, lmNorm); } updateResidualsAndCost(); double actRed = -1.0; if (0.1 * cost < previousCost) { double r = cost / previousCost; actRed = 1.0 - r * r; } for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; double dirJ = lmDir[pj]; work1[j] = 0; int index = pj; for (int i = 0; i <= j; ++i) { work1[i] += jacobian[index] * dirJ; index += cols; } } double coeff1 = 0; for (int j = 0; j < solvedCols; ++j) { coeff1 += work1[j] * work1[j]; } double pc2 = previousCost * previousCost; coeff1 = coeff1 / pc2; double coeff2 = lmPar * lmNorm * lmNorm / pc2; double preRed = coeff1 + 2 * coeff2; double dirDer = -(coeff1 + coeff2); ratio = (preRed == 0) ? 0 : (actRed / preRed); if (ratio <= 0.25) { double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5; if ((0.1 * cost >= previousCost) || (tmp < 0.1)) { tmp = 0.1; } delta = tmp * Math.min(delta, 10.0 * lmNorm); lmPar /= tmp; } else if ((lmPar == 0) || (ratio >= 0.75)) { delta = 2 * lmNorm; lmPar *= 0.5; } if (ratio >= 1.0e-4) { firstIteration = false; xNorm = 0; for (int k = 0; k < cols; ++k) { double xK = diag[k] * parameters[k].getEstimate(); xNorm += xK * xK; } xNorm = Math.sqrt(xNorm); } else { cost = previousCost; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; parameters[pj].setEstimate(oldX[pj]); } tmpVec = residuals; residuals = oldRes; oldRes = tmpVec; } if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) { return; } if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) { throw new EstimationException(\\\"cost relative tolerance is too small ({0}),\\\" + \\\" no further reduction in the\\\" + \\\" sum of squares is possible\\\", costRelativeTolerance); } else if (delta <= 2.2204e-16 * xNorm) { throw new EstimationException(\\\"parameters relative tolerance is too small\\\" + \\\" ({0}), no further improvement in\\\" + \\\" the approximate solution is possible\\\", parRelativeTolerance); } else if (maxCosine <= 2.2204e-16) { throw new EstimationException(\\\"orthogonality tolerance is too small ({0}),\\\" + \\\" solution is orthogonal to the jacobian\\\", orthoTolerance); } } } }"
                    ],
                    [
                        0.9896717816591263,
                        "private void determineLMParameter(double[] qy, double delta, double[] diag, double[] work1, double[] work2, double[] work3) { for (int j = 0; j < rank; ++j) { lmDir[permutation[j]] = qy[j]; } for (int j = rank; j < cols; ++j) { lmDir[permutation[j]] = 0; } for (int k = rank - 1; k >= 0; --k) { int pk = permutation[k]; double ypk = lmDir[pk] / diagR[pk]; for (int i = 0; i < k; ++i) { lmDir[permutation[i]] -= ypk * jacobian[i][pk]; } lmDir[pk] = ypk; } double dxNorm = 0; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; double s = diag[pj] * lmDir[pj]; work1[pj] = s; dxNorm += s * s; } dxNorm = Math.sqrt(dxNorm); double fp = dxNorm - delta; if (fp <= 0.1 * delta) { lmPar = 0; return; } double sum2; double parl = 0; if (rank == solvedCols) { for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; work1[pj] *= diag[pj] / dxNorm; } sum2 = 0; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; double sum = 0; for (int i = 0; i < j; ++i) { sum += jacobian[i][pj] * work1[permutation[i]]; } double s = (work1[pj] - sum) / diagR[pj]; work1[pj] = s; sum2 += s * s; } parl = fp / (delta * sum2); } sum2 = 0; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; double sum = 0; for (int i = 0; i <= j; ++i) { sum += jacobian[i][pj] * qy[i]; } sum /= diag[pj]; sum2 += sum * sum; } double gNorm = Math.sqrt(sum2); double paru = gNorm / delta; if (paru == 0) { paru = 2.2251e-308 / Math.min(delta, 0.1); } lmPar = Math.min(paru, Math.max(lmPar, parl)); if (lmPar == 0) { lmPar = gNorm / dxNorm; } for (int countdown = 10; countdown >= 0; --countdown) { if (lmPar == 0) { lmPar = Math.max(2.2251e-308, 0.001 * paru); } double sPar = Math.sqrt(lmPar); for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; work1[pj] = sPar * diag[pj]; } determineLMDirection(qy, work1, work2, work3); dxNorm = 0; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; double s = diag[pj] * lmDir[pj]; work3[pj] = s; dxNorm += s * s; } dxNorm = Math.sqrt(dxNorm); double previousFP = fp; fp = dxNorm - delta; if ((Math.abs(fp) <= 0.1 * delta) || ((parl == 0) && (fp <= previousFP) && (previousFP < 0))) { return; } for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; work1[pj] = work3[pj] * diag[pj] / dxNorm; } for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; work1[pj] /= work2[j]; double tmp = work1[pj]; for (int i = j + 1; i < solvedCols; ++i) { work1[permutation[i]] -= jacobian[i][pj] * tmp; } } sum2 = 0; for (int j = 0; j < solvedCols; ++j) { double s = work1[permutation[j]]; sum2 += s * s; } double correction = fp / (delta * sum2); if (fp > 0) { parl = Math.max(parl, lmPar); } else if (fp < 0) { paru = Math.min(paru, lmPar); } lmPar = Math.max(parl, lmPar + correction); } }"
                    ],
                    [
                        0.9881602674722672,
                        "private void determineLMParameter(double[] qy, double delta, double[] diag, double[] work1, double[] work2, double[] work3) { for (int j = 0; j < rank; ++j) { lmDir[permutation[j]] = qy[j]; } for (int j = rank; j < cols; ++j) { lmDir[permutation[j]] = 0; } for (int k = rank - 1; k >= 0; --k) { int pk = permutation[k]; double ypk = lmDir[pk] / diagR[pk]; int index = pk; for (int i = 0; i < k; ++i) { lmDir[permutation[i]] -= ypk * jacobian[index]; index += cols; } lmDir[pk] = ypk; } double dxNorm = 0; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; double s = diag[pj] * lmDir[pj]; work1[pj] = s; dxNorm += s * s; } dxNorm = Math.sqrt(dxNorm); double fp = dxNorm - delta; if (fp <= 0.1 * delta) { lmPar = 0; return; } double sum2; double parl = 0; if (rank == solvedCols) { for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; work1[pj] *= diag[pj] / dxNorm; } sum2 = 0; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; double sum = 0; int index = pj; for (int i = 0; i < j; ++i) { sum += jacobian[index] * work1[permutation[i]]; index += cols; } double s = (work1[pj] - sum) / diagR[pj]; work1[pj] = s; sum2 += s * s; } parl = fp / (delta * sum2); } sum2 = 0; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; double sum = 0; int index = pj; for (int i = 0; i <= j; ++i) { sum += jacobian[index] * qy[i]; index += cols; } sum /= diag[pj]; sum2 += sum * sum; } double gNorm = Math.sqrt(sum2); double paru = gNorm / delta; if (paru == 0) { paru = 2.2251e-308 / Math.min(delta, 0.1); } lmPar = Math.min(paru, Math.max(lmPar, parl)); if (lmPar == 0) { lmPar = gNorm / dxNorm; } for (int countdown = 10; countdown >= 0; --countdown) { if (lmPar == 0) { lmPar = Math.max(2.2251e-308, 0.001 * paru); } double sPar = Math.sqrt(lmPar); for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; work1[pj] = sPar * diag[pj]; } determineLMDirection(qy, work1, work2, work3); dxNorm = 0; for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; double s = diag[pj] * lmDir[pj]; work3[pj] = s; dxNorm += s * s; } dxNorm = Math.sqrt(dxNorm); double previousFP = fp; fp = dxNorm - delta; if ((Math.abs(fp) <= 0.1 * delta) || ((parl == 0) && (fp <= previousFP) && (previousFP < 0))) { return; } for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; work1[pj] = work3[pj] * diag[pj] / dxNorm; } for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; work1[pj] /= work2[j]; double tmp = work1[pj]; for (int i = j + 1; i < solvedCols; ++i) { work1[permutation[i]] -= jacobian[i * cols + pj] * tmp; } } sum2 = 0; for (int j = 0; j < solvedCols; ++j) { double s = work1[permutation[j]]; sum2 += s * s; } double correction = fp / (delta * sum2); if (fp > 0) { parl = Math.max(parl, lmPar); } else if (fp < 0) { paru = Math.min(paru, lmPar); } lmPar = Math.max(parl, lmPar + correction); } }"
                    ],
                    [
                        0.9879526942968369,
                        "@Override public double integrate(final FirstOrderDifferentialEquations equations, final double t0, final double[] y0, final double t, final double[] y) throws DerivativeException, IntegratorException { final int n = y0.length; sanityChecks(equations, t0, y0, t, y); setEquations(equations); resetEvaluations(); final boolean forward = t > t0; if (y != y0) { System.arraycopy(y0, 0, y, 0, n); } final double[] yDot = new double[n]; final double[] yTmp = new double[y0.length]; final NordsieckStepInterpolator interpolator = new NordsieckStepInterpolator(); interpolator.reinitialize(y, forward); final NordsieckStepInterpolator interpolatorTmp = new NordsieckStepInterpolator(); interpolatorTmp.reinitialize(yTmp, forward); for (StepHandler handler : stepHandlers) { handler.reset(); } CombinedEventsManager manager = addEndTimeChecker(t0, t, eventsHandlersManager); start(t0, y, t); interpolator.reinitialize(stepStart, stepSize, scaled, nordsieck); interpolator.storeTime(stepStart); final int lastRow = nordsieck.getRowDimension() - 1; double hNew = stepSize; interpolator.rescale(hNew); boolean lastStep = false; while (!lastStep) { interpolator.shift(); double error = 0; for (boolean loop = true; loop; ) { stepSize = hNew; error = 0; for (int i = 0; i < y0.length; ++i) { final double yScale = Math.abs(y[i]); final double tol = (vecAbsoluteTolerance == null) ? (scalAbsoluteTolerance + scalRelativeTolerance * yScale) : (vecAbsoluteTolerance[i] + vecRelativeTolerance[i] * yScale); final double ratio = nordsieck.getEntry(lastRow, i) / tol; error += ratio * ratio; } error = Math.sqrt(error / y0.length); if (error <= 1.0) { final double stepEnd = stepStart + stepSize; interpolator.setInterpolatedTime(stepEnd); System.arraycopy(interpolator.getInterpolatedState(), 0, yTmp, 0, y0.length); computeDerivatives(stepEnd, yTmp, yDot); final double[] predictedScaled = new double[y0.length]; for (int j = 0; j < y0.length; ++j) { predictedScaled[j] = stepSize * yDot[j]; } final Array2DRowRealMatrix nordsieckTmp = updateHighOrderDerivativesPhase1(nordsieck); updateHighOrderDerivativesPhase2(scaled, predictedScaled, nordsieckTmp); interpolatorTmp.reinitialize(stepEnd, stepSize, predictedScaled, nordsieckTmp); interpolatorTmp.storeTime(stepStart); interpolatorTmp.shift(); interpolatorTmp.storeTime(stepEnd); if (manager.evaluateStep(interpolatorTmp)) { final double dt = manager.getEventTime() - stepStart; if (Math.abs(dt) <= Math.ulp(stepStart)) { interpolator.storeTime(stepStart); System.arraycopy(y, 0, yTmp, 0, y0.length); hNew = 0; stepSize = 0; loop = false; } else { hNew = dt; interpolator.rescale(hNew); } } else { scaled = predictedScaled; nordsieck = nordsieckTmp; interpolator.reinitialize(stepEnd, stepSize, scaled, nordsieck); loop = false; } } else { final double factor = computeStepGrowShrinkFactor(error); hNew = filterStep(stepSize * factor, forward, false); interpolator.rescale(hNew); } } final double nextStep = stepStart + stepSize; System.arraycopy(yTmp, 0, y, 0, n); interpolator.storeTime(nextStep); manager.stepAccepted(nextStep, y); lastStep = manager.stop(); for (StepHandler handler : stepHandlers) { interpolator.setInterpolatedTime(nextStep); handler.handleStep(interpolator, lastStep); } stepStart = nextStep; if (!lastStep && manager.reset(stepStart, y)) { start(stepStart, y, t); interpolator.reinitialize(stepStart, stepSize, scaled, nordsieck); } if (!lastStep) { stepSize = filterStep(stepSize, forward, true); final double factor = computeStepGrowShrinkFactor(error); final double scaledH = stepSize * factor; final double nextT = stepStart + scaledH; final boolean nextIsLast = forward ? (nextT >= t) : (nextT <= t); hNew = filterStep(scaledH, forward, nextIsLast); interpolator.rescale(hNew); } } final double stopTime = stepStart; stepStart = Double.NaN; stepSize = Double.NaN; return stopTime; }"
                    ],
                    [
                        0.9871638268232346,
                        "private void determineLMDirection(double[] qy, double[] diag, double[] lmDiag, double[] work) { for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; for (int i = j + 1; i < solvedCols; ++i) { jacobian[i * cols + pj] = jacobian[j * cols + permutation[i]]; } lmDir[j] = diagR[pj]; work[j] = qy[j]; } for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; double dpj = diag[pj]; if (dpj != 0) { Arrays.fill(lmDiag, j + 1, lmDiag.length, 0); } lmDiag[j] = dpj; double qtbpj = 0; for (int k = j; k < solvedCols; ++k) { int pk = permutation[k]; if (lmDiag[k] != 0) { final double sin; final double cos; double rkk = jacobian[k * cols + pk]; if (Math.abs(rkk) < Math.abs(lmDiag[k])) { final double cotan = rkk / lmDiag[k]; sin = 1.0 / Math.sqrt(1.0 + cotan * cotan); cos = sin * cotan; } else { final double tan = lmDiag[k] / rkk; cos = 1.0 / Math.sqrt(1.0 + tan * tan); sin = cos * tan; } jacobian[k * cols + pk] = cos * rkk + sin * lmDiag[k]; final double temp = cos * work[k] + sin * qtbpj; qtbpj = -sin * work[k] + cos * qtbpj; work[k] = temp; for (int i = k + 1; i < solvedCols; ++i) { double rik = jacobian[i * cols + pk]; final double temp2 = cos * rik + sin * lmDiag[i]; lmDiag[i] = -sin * rik + cos * lmDiag[i]; jacobian[i * cols + pk] = temp2; } } } int index = j * cols + permutation[j]; lmDiag[j] = jacobian[index]; jacobian[index] = lmDir[j]; } int nSing = solvedCols; for (int j = 0; j < solvedCols; ++j) { if ((lmDiag[j] == 0) && (nSing == solvedCols)) { nSing = j; } if (nSing < solvedCols) { work[j] = 0; } } if (nSing > 0) { for (int j = nSing - 1; j >= 0; --j) { int pj = permutation[j]; double sum = 0; for (int i = j + 1; i < nSing; ++i) { sum += jacobian[i * cols + pj] * work[i]; } work[j] = (work[j] - sum) / lmDiag[j]; } } for (int j = 0; j < lmDir.length; ++j) { lmDir[permutation[j]] = work[j]; } }"
                    ],
                    [
                        0.9867660850286484,
                        "private void determineLMDirection(double[] qy, double[] diag, double[] lmDiag, double[] work) { for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; for (int i = j + 1; i < solvedCols; ++i) { jacobian[i][pj] = jacobian[j][permutation[i]]; } lmDir[j] = diagR[pj]; work[j] = qy[j]; } for (int j = 0; j < solvedCols; ++j) { int pj = permutation[j]; double dpj = diag[pj]; if (dpj != 0) { Arrays.fill(lmDiag, j + 1, lmDiag.length, 0); } lmDiag[j] = dpj; double qtbpj = 0; for (int k = j; k < solvedCols; ++k) { int pk = permutation[k]; if (lmDiag[k] != 0) { final double sin; final double cos; double rkk = jacobian[k][pk]; if (Math.abs(rkk) < Math.abs(lmDiag[k])) { final double cotan = rkk / lmDiag[k]; sin = 1.0 / Math.sqrt(1.0 + cotan * cotan); cos = sin * cotan; } else { final double tan = lmDiag[k] / rkk; cos = 1.0 / Math.sqrt(1.0 + tan * tan); sin = cos * tan; } jacobian[k][pk] = cos * rkk + sin * lmDiag[k]; final double temp = cos * work[k] + sin * qtbpj; qtbpj = -sin * work[k] + cos * qtbpj; work[k] = temp; for (int i = k + 1; i < solvedCols; ++i) { double rik = jacobian[i][pk]; final double temp2 = cos * rik + sin * lmDiag[i]; lmDiag[i] = -sin * rik + cos * lmDiag[i]; jacobian[i][pk] = temp2; } } } lmDiag[j] = jacobian[j][permutation[j]]; jacobian[j][permutation[j]] = lmDir[j]; } int nSing = solvedCols; for (int j = 0; j < solvedCols; ++j) { if ((lmDiag[j] == 0) && (nSing == solvedCols)) { nSing = j; } if (nSing < solvedCols) { work[j] = 0; } } if (nSing > 0) { for (int j = nSing - 1; j >= 0; --j) { int pj = permutation[j]; double sum = 0; for (int i = j + 1; i < nSing; ++i) { sum += jacobian[i][pj] * work[i]; } work[j] = (work[j] - sum) / lmDiag[j]; } } for (int j = 0; j < lmDir.length; ++j) { lmDir[permutation[j]] = work[j]; } }"
                    ]
                ],
                "non_directly_related_tests": [
                    "org.apache.commons.math.optimization.general.MinpackTest::testMinpackJennrichSampson",
                    "org.apache.commons.math.optimization.general.MinpackTest::testMinpackFreudensteinRoth"
                ],
                "generation": {
                    "1": {
                        "prompt": "You are an expert Java developer. Below are buggy method(s) from a large Java project. These methods cause one or more test failures.\nYour task is to fix the bugs in these methods. Use the provided test failure(s) to guide your reasoning.\n\n---\n\n## Buggy Methods\n\n\n```java\n    /**\n     * Build an optimizer for least squares problems.\n     * <p>The default values for the algorithm settings are:\n     *   <ul>\n     *    <li>{@link #setConvergenceChecker vectorial convergence checker}: null</li>\n     *    <li>{@link #setInitialStepBoundFactor initial step bound factor}: 100.0</li>\n     *    <li>{@link #setMaxIterations maximal iterations}: 1000</li>\n     *    <li>{@link #setCostRelativeTolerance cost relative tolerance}: 1.0e-10</li>\n     *    <li>{@link #setParRelativeTolerance parameters relative tolerance}: 1.0e-10</li>\n     *    <li>{@link #setOrthoTolerance orthogonality tolerance}: 1.0e-10</li>\n     *   </ul>\n     * </p>\n     * <p>These default values may be overridden after construction. If the {@link\n     * #setConvergenceChecker vectorial convergence checker} is set to a non-null value, it\n     * will be used instead of the {@link #setCostRelativeTolerance cost relative tolerance}\n     * and {@link #setParRelativeTolerance parameters relative tolerance} settings.\n     */\n\n    public LevenbergMarquardtOptimizer() {\n\n        // set up the superclass with a default  max cost evaluations setting\n        setMaxIterations(1000);\n\n        // default values for the tuning parameters\n        setInitialStepBoundFactor(100.0);\n        setCostRelativeTolerance(1.0e-10);\n        setParRelativeTolerance(1.0e-10);\n        setOrthoTolerance(1.0e-10);\n\n    }\n\n```\n\n```java\n    /** {@inheritDoc} */\n\n    @Override\n    protected VectorialPointValuePair doOptimize()\n        throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n\n        // arrays shared with the other private methods\n        solvedCols  = Math.min(rows, cols);\n        diagR       = new double[cols];\n        jacNorm     = new double[cols];\n        beta        = new double[cols];\n        permutation = new int[cols];\n        lmDir       = new double[cols];\n\n        // local point\n        double   delta   = 0;\n        double   xNorm   = 0;\n        double[] diag    = new double[cols];\n        double[] oldX    = new double[cols];\n        double[] oldRes  = new double[rows];\n        double[] work1   = new double[cols];\n        double[] work2   = new double[cols];\n        double[] work3   = new double[cols];\n\n        // evaluate the function at the starting point and calculate its norm\n        updateResidualsAndCost();\n\n        // outer loop\n        lmPar = 0;\n        boolean firstIteration = true;\n        while (true) {\n\n            incrementIterationsCounter();\n\n            // compute the Q.R. decomposition of the jacobian matrix\n            updateJacobian();\n            qrDecomposition();\n\n            // compute Qt.res\n            qTy(residuals);\n\n            // now we don't need Q anymore,\n            // so let jacobian contain the R matrix with its diagonal elements\n            for (int k = 0; k < solvedCols; ++k) {\n                int pk = permutation[k];\n                jacobian[k][pk] = diagR[pk];\n            }\n\n            if (firstIteration) {\n\n                // scale the point according to the norms of the columns\n                // of the initial jacobian\n                xNorm = 0;\n                for (int k = 0; k < cols; ++k) {\n                    double dk = jacNorm[k];\n                    if (dk == 0) {\n                        dk = 1.0;\n                    }\n                    double xk = dk * point[k];\n                    xNorm  += xk * xk;\n                    diag[k] = dk;\n                }\n                xNorm = Math.sqrt(xNorm);\n\n                // initialize the step bound delta\n                delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n\n            }\n\n            // check orthogonality between function vector and jacobian columns\n            double maxCosine = 0;\n            if (cost != 0) {\n                for (int j = 0; j < solvedCols; ++j) {\n                    int    pj = permutation[j];\n                    double s  = jacNorm[pj];\n                    if (s != 0) {\n                        double sum = 0;\n                        for (int i = 0; i <= j; ++i) {\n                            sum += jacobian[i][pj] * residuals[i];\n                        }\n                        maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n                    }\n                }\n            }\n            if (maxCosine <= orthoTolerance) {\n                // convergence has been reached\n                return new VectorialPointValuePair(point, objective);\n            }\n\n            // rescale if necessary\n            for (int j = 0; j < cols; ++j) {\n                diag[j] = Math.max(diag[j], jacNorm[j]);\n            }\n\n            // inner loop\n            for (double ratio = 0; ratio < 1.0e-4;) {\n\n                // save the state\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    oldX[pj] = point[pj];\n                }\n                double previousCost = cost;\n                double[] tmpVec = residuals;\n                residuals = oldRes;\n                oldRes    = tmpVec;\n\n                // determine the Levenberg-Marquardt parameter\n                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n\n                // compute the new point and the norm of the evolution direction\n                double lmNorm = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    lmDir[pj] = -lmDir[pj];\n                    point[pj] = oldX[pj] + lmDir[pj];\n                    double s = diag[pj] * lmDir[pj];\n                    lmNorm  += s * s;\n                }\n                lmNorm = Math.sqrt(lmNorm);\n\n                // on the first iteration, adjust the initial step bound.\n                if (firstIteration) {\n                    delta = Math.min(delta, lmNorm);\n                }\n\n                // evaluate the function at x + p and calculate its norm\n                updateResidualsAndCost();\n\n                // compute the scaled actual reduction\n                double actRed = -1.0;\n                if (0.1 * cost < previousCost) {\n                    double r = cost / previousCost;\n                    actRed = 1.0 - r * r;\n                }\n\n                // compute the scaled predicted reduction\n                // and the scaled directional derivative\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    double dirJ = lmDir[pj];\n                    work1[j] = 0;\n                    for (int i = 0; i <= j; ++i) {\n                        work1[i] += jacobian[i][pj] * dirJ;\n                    }\n                }\n                double coeff1 = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    coeff1 += work1[j] * work1[j];\n                }\n                double pc2 = previousCost * previousCost;\n                coeff1 = coeff1 / pc2;\n                double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n                double preRed = coeff1 + 2 * coeff2;\n                double dirDer = -(coeff1 + coeff2);\n\n                // ratio of the actual to the predicted reduction\n                ratio = (preRed == 0) ? 0 : (actRed / preRed);\n\n                // update the step bound\n                if (ratio <= 0.25) {\n                    double tmp =\n                        (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n                        if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {\n                            tmp = 0.1;\n                        }\n                        delta = tmp * Math.min(delta, 10.0 * lmNorm);\n                        lmPar /= tmp;\n                } else if ((lmPar == 0) || (ratio >= 0.75)) {\n                    delta = 2 * lmNorm;\n                    lmPar *= 0.5;\n                }\n\n                // test for successful iteration.\n                if (ratio >= 1.0e-4) {\n                    // successful iteration, update the norm\n                    firstIteration = false;\n                    xNorm = 0;\n                    for (int k = 0; k < cols; ++k) {\n                        double xK = diag[k] * point[k];\n                        xNorm    += xK * xK;\n                    }\n                    xNorm = Math.sqrt(xNorm);\n                } else {\n                    // failed iteration, reset the previous values\n                    cost = previousCost;\n                    for (int j = 0; j < solvedCols; ++j) {\n                        int pj = permutation[j];\n                        point[pj] = oldX[pj];\n                    }\n                    tmpVec    = residuals;\n                    residuals = oldRes;\n                    oldRes    = tmpVec;\n                }\n\n                // tests for convergence.\n                    // we use the vectorial convergence checker\n                    // we use the Levenberg-Marquardt specific convergence parameters\n                    if (((Math.abs(actRed) <= costRelativeTolerance) &&\n                         (preRed <= costRelativeTolerance) &&\n                         (ratio <= 2.0)) ||\n                        (delta <= parRelativeTolerance * xNorm)) {\n                        return new VectorialPointValuePair(point, objective);\n                    }\n\n                // tests for termination and stringent tolerances\n                // (2.2204e-16 is the machine epsilon for IEEE754)\n                if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n                    throw new OptimizationException(\"cost relative tolerance is too small ({0}),\" +\n                            \" no further reduction in the\" +\n                            \" sum of squares is possible\",\n                            costRelativeTolerance);\n                } else if (delta <= 2.2204e-16 * xNorm) {\n                    throw new OptimizationException(\"parameters relative tolerance is too small\" +\n                            \" ({0}), no further improvement in\" +\n                            \" the approximate solution is possible\",\n                            parRelativeTolerance);\n                } else if (maxCosine <= 2.2204e-16)  {\n                    throw new OptimizationException(\"orthogonality tolerance is too small ({0}),\" +\n                            \" solution is orthogonal to the jacobian\",\n                            orthoTolerance);\n                }\n\n            }\n\n        }\n\n    }\n\n```\n\n---\n\n## Failing Test Case(s)\n\n \n#Test method 1:\n```java\n  public void testMinpackJennrichSampson() {\n    minpackTest(new JennrichSampsonFunction(10, new double[] { 0.3, 0.4 },\n                                            64.5856498144943, 11.1517793413499,\n                                            new double[] {\n                                             0.2578330049, 0.257829976764542\n                                            }), false);\n  }\n```\n#Error message from the test method 1: junit.framework.AssertionFailedError: expected:<0.2578330049> but was:<0.257819926636807>\n \n#Test method 2:\n```java\n  public void testMinpackFreudensteinRoth() {\n    minpackTest(new FreudensteinRothFunction(new double[] { 0.5, -2.0 },\n                                             20.0124960961895, 6.99887517584575,\n                                             new double[] {\n                                               11.4124844654993,\n                                               -0.896827913731509\n                                             }), false);\n    minpackTest(new FreudensteinRothFunction(new double[] { 5.0, -20.0 },\n                                             12432.833948863, 6.9988751744895,\n                                             new double[] {\n                                               11.4121122022341,\n                                               -0.8968550851268697\n                                             }), false);\n    minpackTest(new FreudensteinRothFunction(new double[] { 50.0, -200.0 },\n                                             11426454.595762, 6.99887517242903,\n                                             new double[] {\n                                               11.412069435091231,\n                                               -0.8968582807605691\n                                             }), false);\n  }\n```\n#Error message from the test method 2: junit.framework.AssertionFailedError: expected:<11.4121122022341> but was:<11.41300466147456>\n\n---\n\n## Your Goal\n\nFix the buggy methods. Return only the fixed Java methods. Do not include explanations or other text.\n",
                        "patches": [
                            "\n    /** {@inheritDoc} */\n\n    @Override\n    protected VectorialPointValuePair doOptimize()\n        throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n\n        // arrays shared with the other private methods\n        solvedCols  = Math.min(rows, cols);\n        diagR       = new double[cols];\n        jacNorm     = new double[cols];\n        beta        = new double[cols];\n        permutation = new int[cols];\n        lmDir       = new double[cols];\n\n        // local point\n        double   delta   = 0;\n        double   xNorm   = 0;\n        double[] diag    = new double[cols];\n        double[] oldX    = new double[cols];\n        double[] oldRes  = new double[rows];\n        double[] work1   = new double[cols];\n        double[] work2   = new double[cols];\n        double[] work3   = new double[cols];\n\n        // evaluate the function at the starting point and calculate its norm\n        updateResidualsAndCost();\n\n        // outer loop\n        lmPar = 0;\n        boolean firstIteration = true;\n        while (true) {\n\n            incrementIterationsCounter();\n\n            // compute the Q.R. decomposition of the jacobian matrix\n            updateJacobian();\n            qrDecomposition();\n\n            // compute Qt.res\n            qTy(residuals);\n\n            // now we don't need Q anymore,\n            // so let jacobian contain the R matrix with its diagonal elements\n            for (int k = 0; k < solvedCols; ++k) {\n                int pk = permutation[k];\n                jacobian[k][pk] = diagR[pk];\n            }\n\n            if (firstIteration) {\n\n                // scale the point according to the norms of the columns\n                // of the initial jacobian\n                xNorm = 0;\n                for (int k = 0; k < cols; ++k) {\n                    double dk = jacNorm[k];\n                    if (dk == 0) {\n                        dk = 1.0;\n                    }\n                    double xk = dk * point[k];\n                    xNorm  += xk * xk;\n                    diag[k] = dk;\n                }\n                xNorm = Math.sqrt(xNorm);\n\n                // initialize the step bound delta\n                delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n\n            }\n\n            // check orthogonality between function vector and jacobian columns\n            double maxCosine = 0;\n            if (cost != 0) {\n                for (int j = 0; j < solvedCols; ++j) {\n                    int    pj = permutation[j];\n                    double s  = jacNorm[pj];\n                    if (s != 0) {\n                        double sum = 0;\n                        for (int i = 0; i <= j; ++i) {\n                            sum += jacobian[i][pj] * residuals[i];\n                        }\n                        maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n                    }\n                }\n            }\n            if (maxCosine <= orthoTolerance) {\n                // convergence has been reached\n                return new VectorialPointValuePair(point, objective);\n            }\n\n            // rescale if necessary\n            for (int j = 0; j < cols; ++j) {\n                diag[j] = Math.max(diag[j], jacNorm[j]);\n            }\n\n            // inner loop\n            for (double ratio = 0; ratio < 1.0e-4;) {\n\n                // save the state\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    oldX[pj] = point[pj];\n                }\n                double previousCost = cost;\n                double[] tmpVec = residuals;\n                residuals = oldRes;\n                oldRes    = tmpVec;\n\n                // determine the Levenberg-Marquardt parameter\n                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n\n                // compute the new point and the norm of the evolution direction\n                double lmNorm = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    lmDir[pj] = -lmDir[pj];\n                    point[pj] = oldX[pj] + lmDir[pj];\n                    double s = diag[pj] * lmDir[pj];\n                    lmNorm  += s * s;\n                }\n                lmNorm = Math.sqrt(lmNorm);\n\n                // on the first iteration, adjust the initial step bound.\n                if (firstIteration) {\n                    delta = Math.min(delta, lmNorm);\n                }\n\n                // evaluate the function at x + p and calculate its norm\n                updateResidualsAndCost();\n\n                // compute the scaled actual reduction\n                double actRed = -1.0;\n                if (0.1 * cost < previousCost) {\n                    double r = cost / previousCost;\n                    actRed = 1.0 - r * r;\n                }\n\n                // compute the scaled predicted reduction\n                // and the scaled directional derivative\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    double dirJ = lmDir[pj];\n                    work1[j] = 0;\n                    for (int i = 0; i <= j; ++i) {\n                        work1[i] += jacobian[i][pj] * dirJ;\n                    }\n                }\n                double coeff1 = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    coeff1 += work1[j] * work1[j];\n                }\n                double pc2 = previousCost * previousCost;\n                coeff1 = coeff1 / pc2;\n                double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n                double preRed = coeff1 + 2 * coeff2;\n                double dirDer = -(coeff1 + coeff2);\n\n                // ratio of the actual to the predicted reduction\n                ratio = (preRed == 0) ? 0 : (actRed / preRed);\n\n                // update the step bound\n                if (ratio <= 0.25) {\n                    double tmp =\n                        (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n                        if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {\n                            tmp = 0.1;\n                        }\n                        delta = tmp * Math.min(delta, 10.0 * lmNorm);\n                        lmPar /= tmp;\n                } else if ((lmPar == 0) || (ratio >= 0.75)) {\n                    delta = 2 * lmNorm;\n                    lmPar *= 0.5;\n                }\n\n                // test for successful iteration.\n                if (ratio >= 1.0e-4) {\n                    // successful iteration, update the norm\n                    firstIteration = false;\n                    xNorm = 0;\n                    for (int k = 0; k < cols; ++k) {\n                        double xK = diag[k] * point[k];\n                        xNorm    += xK * xK;\n                    }\n                    xNorm = Math.sqrt(xNorm);\n                } else {\n                    // failed iteration, reset the previous values\n                    cost = previousCost;\n                    for (int j = 0; j < solvedCols; ++j) {\n                        int pj = permutation[j];\n                        point[pj] = oldX[pj];\n                    }\n                    tmpVec    = residuals;\n                    residuals = oldRes;\n                    oldRes    = tmpVec;\n                }\n\n                // tests for convergence\n                boolean converged = false;\n                if (((Math.abs(actRed) <= costRelativeTolerance) ||\n                     (preRed <= costRelativeTolerance) ||\n                     (ratio <= 2.0)) &&\n                    (delta <= parRelativeTolerance * xNorm)) {\n                    converged = true;\n                }\n\n                if (converged) {\n                    return new VectorialPointValuePair(point, objective);\n                }\n\n                // tests for termination and stringent tolerances\n                if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n                    throw new OptimizationException(\"cost relative tolerance is too small ({0}),\" +\n                            \" no further reduction in the\" +\n                            \" sum of squares is possible\",\n                            costRelativeTolerance);\n                } else if (delta <= 2.2204e-16 * xNorm) {\n                    throw new OptimizationException(\"parameters relative tolerance is too small\" +\n                            \" ({0}), no further improvement in\" +\n                            \" the approximate solution is possible\",\n                            parRelativeTolerance);\n                } else if (maxCosine <= 2.2204e-16)  {\n                    throw new OptimizationException(\"orthogonality tolerance is too small ({0}),\" +\n                            \" solution is orthogonal to the jacobian\",\n                            orthoTolerance);\n                }\n\n            }\n\n        }\n\n    }\n",
                            "\n    /** {@inheritDoc} */\n\n    @Override\n    protected VectorialPointValuePair doOptimize()\n        throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n\n        // arrays shared with the other private methods\n        solvedCols  = Math.min(rows, cols);\n        diagR       = new double[cols];\n        jacNorm     = new double[cols];\n        beta        = new double[cols];\n        permutation = new int[cols];\n        lmDir       = new double[cols];\n\n        // local point\n        double   delta   = 0;\n        double   xNorm   = 0;\n        double[] diag    = new double[cols];\n        double[] oldX    = new double[cols];\n        double[] oldRes  = new double[rows];\n        double[] work1   = new double[cols];\n        double[] work2   = new double[cols];\n        double[] work3   = new double[cols];\n\n        // evaluate the function at the starting point and calculate its norm\n        updateResidualsAndCost();\n\n        // outer loop\n        lmPar = 0;\n        boolean firstIteration = true;\n        while (true) {\n\n            incrementIterationsCounter();\n\n            // compute the Q.R. decomposition of the jacobian matrix\n            updateJacobian();\n            qrDecomposition();\n\n            // compute Qt.res\n            qTy(residuals);\n\n            // now we don't need Q anymore,\n            // so let jacobian contain the R matrix with its diagonal elements\n            for (int k = 0; k < solvedCols; ++k) {\n                int pk = permutation[k];\n                jacobian[k][pk] = diagR[pk];\n            }\n\n            if (firstIteration) {\n\n                // scale the point according to the norms of the columns\n                // of the initial jacobian\n                xNorm = 0;\n                for (int k = 0; k < cols; ++k) {\n                    double dk = jacNorm[k];\n                    if (dk == 0) {\n                        dk = 1.0;\n                    }\n                    double xk = dk * point[k];\n                    xNorm  += xk * xk;\n                    diag[k] = dk;\n                }\n                xNorm = Math.sqrt(xNorm);\n\n                // initialize the step bound delta\n                delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n\n            } else {\n                // Update maxCosine on subsequent iterations after calculating jacobian\n                double maxCosine = 0;\n                if (cost != 0) {\n                    for (int j = 0; j < solvedCols; ++j) {\n                        int    pj = permutation[j];\n                        double s  = jacNorm[pj];\n                        if (s != 0) {\n                            double sum = 0;\n                            for (int i = 0; i <= j; ++i) {\n                                sum += jacobian[i][pj] * residuals[i];\n                            }\n                            maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n                        }\n                    }\n                }\n                if (maxCosine <= orthoTolerance) {\n                    // convergence has been reached\n                    return new VectorialPointValuePair(point, objective);\n                }\n            }\n\n            // rescale if necessary\n            for (int j = 0; j < cols; ++j) {\n                diag[j] = Math.max(diag[j], jacNorm[j]);\n            }\n\n            // inner loop\n            for (double ratio = 0; ratio < 1.0e-4;) {\n\n                // save the state\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    oldX[pj] = point[pj];\n                }\n                double previousCost = cost;\n                double[] tmpVec = residuals;\n                residuals = oldRes;\n                oldRes    = tmpVec;\n\n                // determine the Levenberg-Marquardt parameter\n                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n\n                // compute the new point and the norm of the evolution direction\n                double lmNorm = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    lmDir[pj] = -lmDir[pj];\n                    point[pj] = oldX[pj] + lmDir[pj];\n                    double s = diag[pj] * lmDir[pj];\n                    lmNorm  += s * s;\n                }\n                lmNorm = Math.sqrt(lmNorm);\n\n                // on the first iteration, adjust the initial step bound.\n                if (firstIteration) {\n                    delta = Math.min(delta, lmNorm);\n                }\n\n                // evaluate the function at x + p and calculate its norm\n                updateResidualsAndCost();\n\n                // compute the scaled actual reduction\n                double actRed = -1.0;\n                if (0.1 * cost < previousCost) {\n                    double r = cost / previousCost;\n                    actRed = 1.0 - r * r;\n                }\n\n                // compute the scaled predicted reduction\n                // and the scaled directional derivative\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    double dirJ = lmDir[pj];\n                    work1[j] = 0;\n                    for (int i = 0; i <= j; ++i) {\n                        work1[i] += jacobian[i][pj] * dirJ;\n                    }\n                }\n                double coeff1 = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    coeff1 += work1[j] * work1[j];\n                }\n                double pc2 = previousCost * previousCost;\n                coeff1 = coeff1 / pc2;\n                double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n                double preRed = coeff1 + 2 * coeff2;\n                double dirDer = -(coeff1 + coeff2);\n\n                // ratio of the actual to the predicted reduction\n                ratio = (preRed == 0) ? 0 : (actRed / preRed);\n\n                // update the step bound\n                if (ratio <= 0.25) {\n                    double tmp =\n                        (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n                        if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {\n                            tmp = 0.1;\n                        }\n                        delta = tmp * Math.min(delta, 10.0 * lmNorm);\n                        lmPar /= tmp;\n                } else if ((lmPar == 0) || (ratio >= 0.75)) {\n                    delta = 2 * lmNorm;\n                    lmPar *= 0.5;\n                }\n\n                // test for successful iteration.\n                if (ratio >= 1.0e-4) {\n                    // successful iteration, update the norm\n                    firstIteration = false;\n                    xNorm = 0;\n                    for (int k = 0; k < cols; ++k) {\n                        double xK = diag[k] * point[k];\n                        xNorm    += xK * xK;\n                    }\n                    xNorm = Math.sqrt(xNorm);\n                } else {\n                    // failed iteration, reset the previous values\n                    cost = previousCost;\n                    for (int j = 0; j < solvedCols; ++j) {\n                        int pj = permutation[j];\n                        point[pj] = oldX[pj];\n                    }\n                    tmpVec    = residuals;\n                    residuals = oldRes;\n                    oldRes    = tmpVec;\n                }\n\n                // tests for convergence.\n                // we use the vectorial convergence checker\n                // we use the Levenberg-Marquardt specific convergence parameters\n                if (((Math.abs(actRed) <= costRelativeTolerance) &&\n                        (preRed <= costRelativeTolerance) &&\n                        (ratio <= 2.0)) ||\n                    (delta <= parRelativeTolerance * xNorm)) {\n                    return new VectorialPointValuePair(point, objective);\n                }\n\n                // tests for termination and stringent tolerances\n                // (2.2204e-16 is the machine epsilon for IEEE754)\n                if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n                    throw new OptimizationException(\"cost relative tolerance is too small ({0}),\" +\n                            \" no further reduction in the\" +\n                            \" sum of squares is possible\",\n                            costRelativeTolerance);\n                } else if (delta <= 2.2204e-16 * xNorm) {\n                    throw new OptimizationException(\"parameters relative tolerance is too small\" +\n                            \" ({0}), no further improvement in\" +\n                            \" the approximate solution is possible\",\n                            parRelativeTolerance);\n                } else if (maxCosine <= 2.2204e-16)  {\n                    throw new OptimizationException(\"orthogonality tolerance is too small ({0}),\" +\n                            \" solution is orthogonal to the jacobian\",\n                            orthoTolerance);\n                }\n\n            }\n\n        }\n\n    }\n",
                            "\n    /** {@inheritDoc} */\n\n    @Override\n    protected VectorialPointValuePair doOptimize()\n        throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n\n        // arrays shared with the other private methods\n        solvedCols  = Math.min(rows, cols);\n        diagR       = new double[cols];\n        jacNorm     = new double[cols];\n        beta        = new double[cols];\n        permutation = new int[cols];\n        lmDir       = new double[cols];\n\n        // local point\n        double   delta   = 0;\n        double   xNorm   = 0;\n        double[] diag    = new double[cols];\n        double[] oldX    = new double[cols];\n        double[] oldRes  = new double[rows];\n        double[] work1   = new double[cols];\n        double[] work2   = new double[cols];\n        double[] work3   = new double[cols];\n\n        // evaluate the function at the starting point and calculate its norm\n        updateResidualsAndCost();\n\n        // outer loop\n        lmPar = 0;\n        boolean firstIteration = true;\n        while (true) {\n\n            incrementIterationsCounter();\n\n            // compute the Q.R. decomposition of the jacobian matrix\n            updateJacobian();\n            qrDecomposition();\n\n            // compute Qt.res\n            qTy(residuals);\n\n            // now we don't need Q anymore,\n            // so let jacobian contain the R matrix with its diagonal elements\n            for (int k = 0; k < solvedCols; ++k) {\n                int pk = permutation[k];\n                jacobian[k][pk] = diagR[pk];\n            }\n\n            if (firstIteration) {\n\n                // scale the point according to the norms of the columns\n                // of the initial jacobian\n                xNorm = 0;\n                for (int k = 0; k < cols; ++k) {\n                    double dk = jacNorm[k];\n                    if (dk == 0) {\n                        dk = 1.0;\n                    }\n                    double xk = dk * point[k];\n                    xNorm  += xk * xk;\n                    diag[k] = dk;\n                }\n                xNorm = Math.sqrt(xNorm);\n\n                // initialize the step bound delta\n                delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n\n            }\n\n            // check orthogonality between function vector and jacobian columns\n            double maxCosine = 0;\n            if (cost != 0) {\n                for (int j = 0; j < solvedCols; ++j) {\n                    int    pj = permutation[j];\n                    double s  = jacNorm[pj];\n                    if (s != 0) {\n                        double sum = 0;\n                        for (int i = 0; i <= j; ++i) {\n                            sum += jacobian[i][pj] * residuals[i];\n                        }\n                        maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n                    }\n                }\n            }\n            if (maxCosine <= orthoTolerance) {\n                // convergence has been reached\n                return new VectorialPointValuePair(point, objective);\n            }\n\n            // rescale if necessary\n            for (int j = 0; j < cols; ++j) {\n                diag[j] = Math.max(diag[j], jacNorm[j]);\n            }\n\n            // inner loop\n            for (double ratio = 0; ratio < 1.0e-4;) {\n\n                // save the state\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    oldX[pj] = point[pj];\n                }\n                double previousCost = cost;\n                double[] tmpVec = residuals;\n                residuals = oldRes;\n                oldRes    = tmpVec;\n\n                // determine the Levenberg-Marquardt parameter\n                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n\n                // compute the new point and the norm of the evolution direction\n                double lmNorm = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    lmDir[pj] = -lmDir[pj];\n                    point[pj] = oldX[pj] + lmDir[pj];\n                    double s = diag[pj] * lmDir[pj];\n                    lmNorm  += s * s;\n                }\n                lmNorm = Math.sqrt(lmNorm);\n\n                // on the first iteration, adjust the initial step bound.\n                if (firstIteration) {\n                    delta = Math.min(delta, lmNorm);\n                }\n\n                // evaluate the function at x + p and calculate its norm\n                updateResidualsAndCost();\n\n                // compute the scaled actual reduction\n                double actRed = -1.0;\n                if (0.1 * cost < previousCost) {\n                    double r = cost / previousCost;\n                    actRed = 1.0 - r * r;\n                }\n\n                // compute the scaled predicted reduction\n                // and the scaled directional derivative\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    double dirJ = lmDir[pj];\n                    work1[j] = 0;\n                    for (int i = 0; i <= j; ++i) {\n                        work1[i] += jacobian[i][pj] * dirJ;\n                    }\n                }\n                double coeff1 = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    coeff1 += work1[j] * work1[j];\n                }\n                double pc2 = previousCost * previousCost;\n                coeff1 = coeff1 / pc2;\n                double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n                double preRed = coeff1 + 2 * coeff2;\n                double dirDer = -(coeff1 + coeff2);\n\n                // ratio of the actual to the predicted reduction\n                ratio = (preRed == 0) ? 0 : (actRed / preRed);\n\n                // update the step bound\n                if (ratio <= 0.25) {\n                    double tmp =\n                        (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n                        if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {\n                            tmp = 0.1;\n                        }\n                        delta = tmp * Math.min(delta, 10.0 * lmNorm);\n                        lmPar /= tmp;\n                } else if ((lmPar == 0) || (ratio >= 0.75)) {\n                    delta = 2 * lmNorm;\n                    lmPar *= 0.5;\n                }\n\n                // test for successful iteration.\n                if (ratio >= 1.0e-4) {\n                    // successful iteration, update the norm\n                    firstIteration = false;\n                    xNorm = 0;\n                    for (int k = 0; k < cols; ++k) {\n                        double xK = diag[k] * point[k];\n                        xNorm    += xK * xK;\n                    }\n                    xNorm = Math.sqrt(xNorm);\n                } else {\n                    // failed iteration, reset the previous values\n                    cost = previousCost;\n                    for (int j = 0; j < solvedCols; ++j) {\n                        int pj = permutation[j];\n                        point[pj] = oldX[pj];\n                    }\n                    tmpVec    = residuals;\n                    residuals = oldRes;\n                    oldRes    = tmpVec;\n                }\n\n                // tests for convergence.\n                    // we use the vectorial convergence checker\n                    // we use the Levenberg-Marquardt specific convergence parameters\n                    if (((Math.abs(actRed) <= costRelativeTolerance * cost) &&\n                         (preRed <= costRelativeTolerance * cost) &&\n                         (ratio <= 2.0)) ||\n                        (delta <= parRelativeTolerance)) {\n                        return new VectorialPointValuePair(point, objective);\n                    }\n\n                // tests for termination and stringent tolerances\n                // (2.2204e-16 is the machine epsilon for IEEE754)\n                if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n                    throw new OptimizationException(\"cost relative tolerance is too small ({0}),\" +\n                            \" no further reduction in the\" +\n                            \" sum of squares is possible\",\n                            costRelativeTolerance);\n                } else if (delta <= 2.2204e-16 * xNorm) {\n                    throw new OptimizationException(\"parameters relative tolerance is too small\" +\n                            \" ({0}), no further improvement in\" +\n                            \" the approximate solution is possible\",\n                            parRelativeTolerance);\n                } else if (maxCosine <= 2.2204e-16)  {\n                    throw new OptimizationException(\"orthogonality tolerance is too small ({0}),\" +\n                            \" solution is orthogonal to the jacobian\",\n                            orthoTolerance);\n                }\n\n            }\n\n        }\n\n    }\n\n",
                            "\n    /** {@inheritDoc} */\n\n    @Override\n    protected VectorialPointValuePair doOptimize()\n        throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n\n        // arrays shared with the other private methods\n        solvedCols  = Math.min(rows, cols);\n        diagR       = new double[cols];\n        jacNorm     = new double[cols];\n        beta        = new double[cols];\n        permutation = new int[cols];\n        lmDir       = new double[cols];\n\n        // local point\n        double   delta   = 0;\n        double   xNorm   = 0;\n        double[] diag    = new double[cols];\n        double[] oldX    = new double[cols];\n        double[] oldRes  = new double[rows];\n        double[] work1   = new double[cols];\n        double[] work2   = new double[cols];\n        double[] work3   = new double[cols];\n\n        // evaluate the function at the starting point and calculate its norm\n        updateResidualsAndCost();\n\n        // outer loop\n        lmPar = 0;\n        boolean firstIteration = true;\n        while (true) {\n\n            incrementIterationsCounter();\n\n            // compute the Q.R. decomposition of the jacobian matrix\n            updateJacobian();\n            qrDecomposition();\n\n            // compute Qt.res\n            qTy(residuals);\n\n            // now we don't need Q anymore,\n            // so let jacobian contain the R matrix with its diagonal elements\n            for (int k = 0; k < solvedCols; ++k) {\n                int pk = permutation[k];\n                jacobian[k][pk] = diagR[pk];\n            }\n\n            if (firstIteration) {\n\n                // scale the point according to the norms of the columns\n                // of the initial jacobian\n                xNorm = 0;\n                for (int k = 0; k < cols; ++k) {\n                    double dk = jacNorm[k];\n                    if (dk == 0) {\n                        dk = 1.0;\n                    }\n                    double xk = dk * point[k];\n                    xNorm  += xk * xk;\n                    diag[k] = dk;\n                }\n                xNorm = Math.sqrt(xNorm);\n\n                // initialize the step bound delta\n                delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n\n            }\n\n            // check orthogonality between function vector and jacobian columns\n            double maxCosine = 0;\n            if (cost != 0) {\n                for (int j = 0; j < solvedCols; ++j) {\n                    int    pj = permutation[j];\n                    double s  = jacNorm[pj];\n                    if (s != 0) {\n                        double sum = 0;\n                        for (int i = 0; i <= j; ++i) {\n                            sum += jacobian[i][pj] * residuals[i];\n                        }\n                        maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n                    }\n                }\n            }\n            if (maxCosine <= orthoTolerance) {\n                // convergence has been reached\n                return new VectorialPointValuePair(point, objective);\n            }\n\n            // rescale if necessary\n            for (int j = 0; j < cols; ++j) {\n                diag[j] = Math.max(diag[j], jacNorm[j]);\n            }\n\n            // inner loop\n            for (double ratio = 0; ratio < 1.0e-4;) {\n\n                // save the state\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    oldX[pj] = point[pj];\n                }\n                double previousCost = cost;\n                double[] tmpVec = residuals;\n                residuals = oldRes;\n                oldRes    = tmpVec;\n\n                // determine the Levenberg-Marquardt parameter\n                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n\n                // compute the new point and the norm of the evolution direction\n                double lmNorm = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    lmDir[pj] = -lmDir[pj];\n                    point[pj] = oldX[pj] + lmDir[pj];\n                    double s = diag[pj] * lmDir[pj];\n                    lmNorm  += s * s;\n                }\n                lmNorm = Math.sqrt(lmNorm);\n\n                // on the first iteration, adjust the initial step bound.\n                if (firstIteration) {\n                    delta = Math.min(delta, lmNorm);\n                }\n\n                // evaluate the function at x + p and calculate its norm\n                updateResidualsAndCost();\n\n                // compute the scaled actual reduction\n                double actRed = -1.0;\n                if (0.1 * cost < previousCost) {\n                    double r = cost / previousCost;\n                    actRed = 1.0 - r * r;\n                }\n\n                // compute the scaled predicted reduction\n                // and the scaled directional derivative\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    double dirJ = lmDir[pj];\n                    work1[j] = 0;\n                    for (int i = 0; i <= j; ++i) {\n                        work1[i] += jacobian[i][pj] * dirJ;\n                    }\n                }\n                double coeff1 = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    coeff1 += work1[j] * work1[j];\n                }\n                double pc2 = previousCost * previousCost;\n                coeff1 = coeff1 / pc2;\n                double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n                double preRed = coeff1 + 2 * coeff2;\n                double dirDer = -(coeff1 + coeff2);\n\n                // ratio of the actual to the predicted reduction\n                ratio = (preRed == 0) ? 0 : (actRed / preRed);\n\n                // update the step bound\n                if (ratio <= 0.25) {\n                    double tmp =\n                        (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n                        if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {\n                            tmp = 0.1;\n                        }\n                        delta = tmp * Math.min(delta, 10.0 * lmNorm);\n                        lmPar /= tmp;\n                } else if ((lmPar == 0) || (ratio >= 0.75)) {\n                    delta = 2 * lmNorm;\n                    lmPar *= 0.5;\n                }\n\n                // test for successful iteration.\n                if (ratio >= 1.0e-4) {\n                    // successful iteration, update the norm\n                    firstIteration = false;\n                    xNorm = 0;\n                    for (int k = 0; k < cols; ++k) {\n                        double xK = diag[k] * point[k];\n                        xNorm    += xK * xK;\n                    }\n                    xNorm = Math.sqrt(xNorm);\n                } else {\n                    // failed iteration, reset the previous values\n                    cost = previousCost;\n                    for (int j = 0; j < solvedCols; ++j) {\n                        int pj = permutation[j];\n                        point[pj] = oldX[pj];\n                    }\n                    tmpVec    = residuals;\n                    residuals = oldRes;\n                    oldRes    = tmpVec;\n                }\n\n                // tests for convergence.\n                    // we use the vectorial convergence checker\n                    // we use the Levenberg-Marquardt specific convergence parameters\n                    if (((Math.abs(actRed) <= costRelativeTolerance) &&\n                         (preRed <= costRelativeTolerance) &&\n                         (ratio <= 2.0)) ||\n                        (delta <= parRelativeTolerance * xNorm)) {\n                        return new VectorialPointValuePair(point, objective);\n                    }\n\n                // tests for termination and stringent tolerances\n                // (2.2204e-16 is the machine epsilon for IEEE754)\n                if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n                    throw new OptimizationException(\"cost relative tolerance is too small ({0}),\" +\n                            \" no further reduction in the\" +\n                            \" sum of squares is possible\",\n                            costRelativeTolerance);\n                } else if (delta <= 2.2204e-16 * xNorm) {\n                    throw new OptimizationException(\"parameters relative tolerance is too small\" +\n                            \" ({0}), no further improvement in\" +\n                            \" the approximate solution is possible\",\n                            parRelativeTolerance);\n                } else if (maxCosine <= 2.2204e-16)  {\n                    throw new OptimizationException(\"orthogonality tolerance is too small ({0}),\" +\n                            \" solution is orthogonal to the jacobian\",\n                            orthoTolerance);\n                }\n\n            }\n\n        }\n\n    }\n\n",
                            "\n    @Override\n    protected VectorialPointValuePair doOptimize()\n        throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n\n        // arrays shared with the other private methods\n        solvedCols  = Math.min(rows, cols);\n        diagR       = new double[cols];\n        jacNorm     = new double[cols];\n        beta        = new double[cols];\n        permutation = new int[cols];\n        lmDir       = new double[cols];\n\n        // local point\n        double   delta   = 0;\n        double   xNorm   = 0;\n        double[] diag    = new double[cols];\n        double[] oldX    = new double[cols];\n        double[] oldRes  = new double[rows];\n        double[] work1   = new double[cols];\n        double[] work2   = new double[cols];\n        double[] work3   = new double[cols];\n\n        // evaluate the function at the starting point and calculate its norm\n        updateResidualsAndCost();\n\n        // outer loop\n        lmPar = 0;\n        boolean firstIteration = true;\n        while (true) {\n\n            incrementIterationsCounter();\n\n            // compute the Q.R. decomposition of the jacobian matrix\n            updateJacobian();\n            qrDecomposition();\n\n            // compute Qt.res\n            qTy(residuals);\n\n            // now we don't need Q anymore,\n            // so let jacobian contain the R matrix with its diagonal elements\n            for (int k = 0; k < solvedCols; ++k) {\n                int pk = permutation[k];\n                jacobian[k][pk] = diagR[pk];\n            }\n\n            if (firstIteration) {\n\n                // scale the point according to the norms of the columns\n                // of the initial jacobian\n                xNorm = 0;\n                for (int k = 0; k < cols; ++k) {\n                    double dk = jacNorm[k];\n                    if (dk == 0) {\n                        dk = 1.0;\n                    }\n                    double xk = dk * point[k];\n                    xNorm  += xk * xk;\n                    diag[k] = dk;\n                }\n                xNorm = Math.sqrt(xNorm);\n\n                // initialize the step bound delta\n                delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n\n            }\n\n            // check orthogonality between function vector and jacobian columns\n            double maxCosine = 0;\n            if (cost != 0) {\n                for (int j = 0; j < solvedCols; ++j) {\n                    int    pj = permutation[j];\n                    double s  = jacNorm[pj];\n                    if (s != 0) {\n                        double sum = 0;\n                        for (int i = 0; i <= j; ++i) {\n                            sum += jacobian[i][pj] * residuals[i];\n                        }\n                        maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n                    }\n                }\n            }\n            if (maxCosine <= orthoTolerance) {\n                // convergence has been reached\n                return new VectorialPointValuePair(point, objective);\n            }\n\n            // rescale if necessary\n            for (int j = 0; j < cols; ++j) {\n                diag[j] = Math.max(diag[j], jacNorm[j]);\n            }\n\n            // inner loop\n            for (double ratio = 0; ratio < 1.0e-4;) {\n\n                // save the state\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    oldX[pj] = point[pj];\n                }\n                double previousCost = cost;\n                double[] tmpVec = residuals;\n                residuals = oldRes;\n                oldRes    = tmpVec;\n\n                // determine the Levenberg-Marquardt parameter\n                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n\n                // compute the new point and the norm of the evolution direction\n                double lmNorm = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    lmDir[pj] = -lmDir[pj];\n                    point[pj] = oldX[pj] + lmDir[pj];\n                    double s = diag[pj] * lmDir[pj];\n                    lmNorm  += s * s;\n                }\n                lmNorm = Math.sqrt(lmNorm);\n\n                // on the first iteration, adjust the initial step bound.\n                if (firstIteration) {\n                    delta = Math.min(delta, lmNorm);\n                }\n\n                // evaluate the function at x + p and calculate its norm\n                updateResidualsAndCost();\n\n                // compute the scaled actual reduction\n                double actRed = -1.0;\n                if (0.1 * cost < previousCost) {\n                    double r = cost / previousCost;\n                    actRed = 1.0 - r * r;\n                }\n\n                // compute the scaled predicted reduction\n                // and the scaled directional derivative\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    double dirJ = lmDir[pj];\n                    work1[j] = 0;\n                    for (int i = 0; i <= j; ++i) {\n                        work1[i] += jacobian[i][pj] * dirJ;\n                    }\n                }\n                double coeff1 = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    coeff1 += work1[j] * work1[j];\n                }\n                double pc2 = previousCost * previousCost;\n                coeff1 = coeff1 / pc2;\n                double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n                double preRed = coeff1 + 2 * coeff2;\n                double dirDer = -(coeff1 + coeff2);\n\n                // ratio of the actual to the predicted reduction\n                ratio = (preRed == 0) ? 0 : (actRed / preRed);\n\n                // update the step bound\n                if (ratio <= 0.25) {\n                    double tmp =\n                        (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n                        if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {\n                            tmp = 0.1;\n                        }\n                        delta = tmp * Math.min(delta, 10.0 * lmNorm);\n                        lmPar /= tmp;\n                } else if ((lmPar == 0) || (ratio >= 0.75)) {\n                    delta = 2 * lmNorm;\n                    lmPar *= 0.5;\n                }\n\n                // test for successful iteration.\n                if (ratio >= 1.0e-4) {\n                    // successful iteration, update the norm\n                    firstIteration = false;\n                    xNorm = 0;\n                    for (int k = 0; k < cols; ++k) {\n                        double xK = diag[k] * point[k];\n                        xNorm    += xK * xK;\n                    }\n                    xNorm = Math.sqrt(xNorm);\n                } else {\n                    // failed iteration, reset the previous values\n                    cost = previousCost;\n                    for (int j = 0; j < solvedCols; ++j) {\n                        int pj = permutation[j];\n                        point[pj] = oldX[pj];\n                    }\n                    tmpVec    = residuals;\n                    residuals = oldRes;\n                    oldRes    = tmpVec;\n                }\n\n                // tests for convergence.\n                if (convergenceChecker != null) {\n                    // we use the vectorial convergence checker\n                    if (convergenceChecker.converged(\n                            getIterations(), new VectorialPointValuePair(oldX, oldRes),\n                            new VectorialPointValuePair(point, residuals))) {\n                        return new VectorialPointValuePair(point, objective);\n                    }\n                } else {\n                    // we use the Levenberg-Marquardt specific convergence parameters\n                    if (((Math.abs(actRed) <= costRelativeTolerance) &&\n                         (preRed <= costRelativeTolerance) &&\n                         (ratio <= 2.0)) ||\n                        (delta <= parRelativeTolerance * xNorm)) {\n                        return new VectorialPointValuePair(point, objective);\n                    }\n                }\n\n                // tests for termination and stringent tolerances\n                // (2.2204e-16 is the machine epsilon for IEEE754)\n                if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n                    throw new OptimizationException(\"cost relative tolerance is too small ({0}),\" +\n                            \" no further reduction in the\" +\n                            \" sum of squares is possible\",\n                            costRelativeTolerance);\n                } else if (delta <= 2.2204e-16 * xNorm) {\n                    throw new OptimizationException(\"parameters relative tolerance is too small\" +\n                            \" ({0}), no further improvement in\" +\n                            \" the approximate solution is possible\",\n                            parRelativeTolerance);\n                } else if (maxCosine <= 2.2204e-16)  {\n                    throw new OptimizationException(\"orthogonality tolerance is too small ({0}),\" +\n                            \" solution is orthogonal to the jacobian\",\n                            orthoTolerance);\n                }\n\n            }\n\n        }\n\n    }\n",
                            "\n    /** {@inheritDoc} */\n\n    @Override\n    protected VectorialPointValuePair doOptimize()\n        throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n\n        // arrays shared with the other private methods\n        solvedCols  = Math.min(rows, cols);\n        diagR       = new double[cols];\n        jacNorm     = new double[cols];\n        beta        = new double[cols];\n        permutation = new int[cols];\n        lmDir       = new double[cols];\n\n        // local point\n        double   delta   = 0;\n        double   xNorm   = 0;\n        double[] diag    = new double[cols];\n        double[] oldX    = new double[cols];\n        double[] oldRes  = new double[rows];\n        double[] work1   = new double[cols];\n        double[] work2   = new double[cols];\n        double[] work3   = new double[cols];\n\n        // evaluate the function at the starting point and calculate its norm\n        updateResidualsAndCost();\n\n        // outer loop\n        lmPar = 0;\n        boolean firstIteration = true;\n        while (true) {\n\n            incrementIterationsCounter();\n\n            // compute the Q.R. decomposition of the jacobian matrix\n            updateJacobian();\n            qrDecomposition();\n\n            // compute Qt.res\n            qTy(residuals);\n\n            // now we don't need Q anymore,\n            // so let jacobian contain the R matrix with its diagonal elements\n            for (int k = 0; k < solvedCols; ++k) {\n                int pk = permutation[k];\n                jacobian[k][pk] = diagR[pk];\n            }\n\n            if (firstIteration) {\n\n                // scale the point according to the norms of the columns\n                // of the initial jacobian\n                xNorm = 0;\n                for (int k = 0; k < cols; ++k) {\n                    double dk = jacNorm[k];\n                    if (dk == 0) {\n                        dk = 1.0;\n                    }\n                    double xk = dk * point[k];\n                    xNorm  += xk * xk;\n                    diag[k] = dk;\n                }\n                xNorm = Math.sqrt(xNorm);\n\n                // initialize the step bound delta\n                delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n\n                // reset the flag\n                firstIteration = false;\n            }\n\n            // check orthogonality between function vector and jacobian columns\n            double maxCosine = 0;\n            if (cost != 0) {\n                for (int j = 0; j < solvedCols; ++j) {\n                    int    pj = permutation[j];\n                    double s  = jacNorm[pj];\n                    if (s != 0) {\n                        double sum = 0;\n                        for (int i = 0; i <= j; ++i) {\n                            sum += jacobian[i][pj] * residuals[i];\n                        }\n                        maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n                    }\n                }\n            }\n            if (maxCosine <= orthoTolerance) {\n                // convergence has been reached\n                return new VectorialPointValuePair(point, objective);\n            }\n\n            // rescale if necessary\n            for (int j = 0; j < cols; ++j) {\n                diag[j] = Math.max(diag[j], jacNorm[j]);\n            }\n\n            // inner loop\n            for (double ratio = 0; ratio < 1.0e-4;) {\n\n                // save the state\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    oldX[pj] = point[pj];\n                }\n                double previousCost = cost;\n                double[] tmpVec = residuals;\n                residuals = oldRes;\n                oldRes    = tmpVec;\n\n                // determine the Levenberg-Marquardt parameter\n                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n\n                // compute the new point and the norm of the evolution direction\n                double lmNorm = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    lmDir[pj] = -lmDir[pj];\n                    point[pj] = oldX[pj] + lmDir[pj];\n                    double s = diag[pj] * lmDir[pj];\n                    lmNorm  += s * s;\n                }\n                lmNorm = Math.sqrt(lmNorm);\n\n                // evaluate the function at x + p and calculate its norm\n                updateResidualsAndCost();\n\n                // compute the scaled actual reduction\n                double actRed = -1.0;\n                double r = cost / previousCost;\n                actRed = 1.0 - r * r;\n\n                // compute the scaled predicted reduction\n                // and the scaled directional derivative\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    double dirJ = lmDir[pj];\n                    work1[j] = 0;\n                    for (int i = 0; i <= j; ++i) {\n                        work1[i] += jacobian[i][pj] * dirJ;\n                    }\n                }\n                double coeff1 = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    coeff1 += work1[j] * work1[j];\n                }\n                double pc2 = previousCost * previousCost;\n                coeff1 = coeff1 / pc2;\n                double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n                double preRed = coeff1 + 2 * coeff2;\n                double dirDer = -(coeff1 + coeff2);\n\n                // ratio of the actual to the predicted reduction\n                ratio = (preRed == 0) ? 0 : (actRed / preRed);\n\n                // update the step bound\n                if (ratio <= 0.25) {\n                    double tmp =\n                        (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n                        if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {\n                            tmp = 0.1;\n                        }\n                        delta = tmp * Math.min(delta, 10.0 * lmNorm);\n                        lmPar /= tmp;\n                } else if ((lmPar == 0) || (ratio >= 0.75)) {\n                    delta = 2 * lmNorm;\n                    lmPar *= 0.5;\n                } else {\n                    delta = lmNorm / 0.5;\n                    lmPar *= 0.5;\n                }\n\n                // test for successful iteration.\n                if (ratio >= 1.0e-4) {\n                    // successful iteration, update the norm\n                    xNorm = 0;\n                    for (int k = 0; k < cols; ++k) {\n                        double xK = diag[k] * point[k];\n                        xNorm    += xK * xK;\n                    }\n                    xNorm = Math.sqrt(xNorm);\n                } else {\n                    // failed iteration, reset the previous values\n                    cost = previousCost;\n                    for (int j = 0; j < solvedCols; ++j) {\n                        int pj = permutation[j];\n                        point[pj] = oldX[pj];\n                    }\n                    tmpVec    = residuals;\n                    residuals = oldRes;\n                    oldRes    = tmpVec;\n                }\n\n                // tests for convergence.\n                    // we use the vectorial convergence checker\n                    // we use the Levenberg-Marquardt specific convergence parameters\n                    if (((Math.abs(actRed) <= costRelativeTolerance) &&\n                         (preRed <= costRelativeTolerance) &&\n                         (ratio <= 2.0)) ||\n                        (delta <= parRelativeTolerance * xNorm)) {\n                        return new VectorialPointValuePair(point, objective);\n                    }\n\n                // tests for termination and stringent tolerances\n                // (2.2204e-16 is the machine epsilon for IEEE754)\n                if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n                    throw new OptimizationException(\"cost relative tolerance is too small ({0}),\" +\n                            \" no further reduction in the\" +\n                            \" sum of squares is possible\",\n                            costRelativeTolerance);\n                } else if (delta <= 2.2204e-16 * xNorm) {\n                    throw new OptimizationException(\"parameters relative tolerance is too small\" +\n                            \" ({0}), no further improvement in\" +\n                            \" the approximate solution is possible\",\n                            parRelativeTolerance);\n                } else if (maxCosine <= 2.2204e-16)  {\n                    throw new OptimizationException(\"orthogonality tolerance is too small ({0}),\" +\n                            \" solution is orthogonal to the jacobian\",\n                            orthoTolerance);\n                }\n\n            }\n\n        }\n\n    }\n",
                            "\n@Override\nprotected VectorialPointValuePair doOptimize()\n    throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n\n    // arrays shared with the other private methods\n    solvedCols  = Math.min(rows, cols);\n    diagR       = new double[cols];\n    jacNorm     = new double[cols];\n    beta        = new double[cols];\n    permutation = new int[cols];\n    lmDir       = new double[cols];\n\n    // local point\n    double   delta   = 0;\n    double   xNorm   = 0;\n    double[] diag    = new double[cols];\n    double[] oldX    = new double[cols];\n    double[] oldRes  = new double[rows];\n    double[] work1   = new double[cols];\n    double[] work2   = new double[cols];\n    double[] work3   = new double[cols];\n\n    // evaluate the function at the starting point and calculate its norm\n    updateResidualsAndCost();\n\n    // outer loop\n    lmPar = 0;\n    boolean firstIteration = true;\n    while (true) {\n\n        incrementIterationsCounter();\n\n        // compute the Q.R. decomposition of the jacobian matrix\n        updateJacobian();\n        qrDecomposition();\n\n        // compute Qt.res\n        qTy(residuals);\n\n        // now we don't need Q anymore,\n        // so let jacobian contain the R matrix with its diagonal elements\n        for (int k = 0; k < solvedCols; ++k) {\n            int pk = permutation[k];\n            jacobian[k][pk] = diagR[pk];\n        }\n\n        if (firstIteration) {\n\n            // scale the point according to the norms of the columns\n            // of the initial jacobian\n            xNorm = 0;\n            for (int k = 0; k < cols; ++k) {\n                double dk = jacNorm[k];\n                if (dk == 0) {\n                    dk = 1.0;\n                }\n                double xk = dk * point[k];\n                xNorm  += xk * xk;\n                diag[k] = dk;\n            }\n            xNorm = Math.sqrt(xNorm);\n\n            // initialize the step bound delta\n            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n\n        }\n\n        // check orthogonality between function vector and jacobian columns\n        double maxCosine = 0;\n        if (cost != 0) {\n            for (int j = 0; j < solvedCols; ++j) {\n                int    pj = permutation[j];\n                double s  = jacNorm[pj];\n                if (s != 0) {\n                    double sum = 0;\n                    for (int i = 0; i <= j; ++i) {\n                        sum += jacobian[i][pj] * residuals[i];\n                    }\n                    maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n                }\n            }\n        }\n        if (maxCosine <= orthoTolerance) {\n            // convergence has been reached\n            return new VectorialPointValuePair(point, objective);\n        }\n\n        // rescale if necessary\n        for (int j = 0; j < cols; ++j) {\n            diag[j] = Math.max(diag[j], jacNorm[j]);\n        }\n\n        // inner loop\n        for (double ratio = 0; ratio < 1.0e-4;) {\n\n            // save the state\n            for (int j = 0; j < solvedCols; ++j) {\n                int pj = permutation[j];\n                oldX[pj] = point[pj];\n            }\n            double previousCost = cost;\n            double[] tmpVec = residuals;\n            residuals = oldRes;\n            oldRes    = tmpVec;\n\n            // determine the Levenberg-Marquardt parameter\n            determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n\n            // compute the new point and the norm of the evolution direction\n            double lmNorm = 0;\n            for (int j = 0; j < solvedCols; ++j) {\n                int pj = permutation[j];\n                lmDir[pj] = -lmDir[pj];\n                point[pj] = oldX[pj] + lmDir[pj];\n                double s = diag[pj] * lmDir[pj];\n                lmNorm  += s * s;\n            }\n            lmNorm = Math.sqrt(lmNorm);\n\n            // on the first iteration, adjust the initial step bound.\n            if (firstIteration) {\n                delta = Math.min(delta, lmNorm);\n            }\n\n            // evaluate the function at x + p and calculate its norm\n            updateResidualsAndCost();\n\n            // compute the scaled actual reduction\n            double actRed = -1.0;\n            if (0.1 * cost < previousCost) {\n                double r = cost / previousCost;\n                actRed = 1.0 - r * r;\n            }\n\n            // compute the scaled predicted reduction\n            // and the scaled directional derivative\n            for (int j = 0; j < solvedCols; ++j) {\n                int pj = permutation[j];\n                double dirJ = lmDir[pj];\n                work1[j] = 0;\n                for (int i = 0; i <= j; ++i) {\n                    work1[i] += jacobian[i][pj] * dirJ;\n                }\n            }\n            double coeff1 = 0;\n            for (int j = 0; j < solvedCols; ++j) {\n                coeff1 += work1[j] * work1[j];\n            }\n            double pc2 = previousCost * previousCost;\n            coeff1 = coeff1 / pc2;\n            double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n            double preRed = coeff1 + 2 * coeff2;\n            double dirDer = -(coeff1 + coeff2);\n\n            // ratio of the actual to the predicted reduction\n            ratio = (preRed == 0) ? 0 : (actRed / preRed);\n\n            // update the step bound\n            if (ratio <= 0.25) {\n                double tmp =\n                    (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n                    if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {\n                        tmp = 0.1;\n                    }\n                    delta = tmp * Math.min(delta, 10.0 * lmNorm);\n                    if (tmp >= 0.1) {  // Ensures lmPar is only updated when tmp >= 0.1\n                        lmPar /= tmp;\n                    }\n            } else if ((lmPar == 0) || (ratio >= 0.75)) {\n                delta = 2 * lmNorm;\n                lmPar *= 0.5;\n            }\n\n            // test for successful iteration.\n            if (ratio >= 1.0e-4) {\n                // successful iteration, update the norm\n                firstIteration = false;\n                xNorm = 0;\n                for (int k = 0; k < cols; ++k) {\n                    double xK = diag[k] * point[k];\n                    xNorm    += xK * xK;\n                }\n                xNorm = Math.sqrt(xNorm);\n            } else {\n                // failed iteration, reset the previous values\n                cost = previousCost;\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    point[pj] = oldX[pj];\n                }\n                tmpVec    = residuals;\n                residuals = oldRes;\n                oldRes    = tmpVec;\n            }\n\n            // tests for convergence.\n            if (((Math.abs(actRed) <= costRelativeTolerance) &&\n                 (preRed <= costRelativeTolerance) &&\n                 (ratio <= 2.0)) ||\n                (delta <= parRelativeTolerance * xNorm)) {\n                return new VectorialPointValuePair(point, objective);\n            }\n\n            // tests for termination and stringent tolerances\n            // (2.2204e-16 is the machine epsilon for IEEE754)\n            if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n                throw new OptimizationException(\"cost relative tolerance is too small ({0}),\" +\n                        \" no further reduction in the\" +\n                        \" sum of squares is possible\",\n                        costRelativeTolerance);\n            } else if (delta <= 2.2204e-16 * xNorm) {\n                throw new OptimizationException(\"parameters relative tolerance is too small\" +\n                        \" ({0}), no further improvement in\" +\n                        \" the approximate solution is possible\",\n                        parRelativeTolerance);\n            } else if (maxCosine <= 2.2204e-16)  {\n                throw new OptimizationException(\"orthogonality tolerance is too small ({0}),\" +\n                        \" solution is orthogonal to the jacobian\",\n                        orthoTolerance);\n            }\n\n        }\n\n    }\n\n}\n",
                            "\n    @Override\n    protected VectorialPointValuePair doOptimize()\n        throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n\n        // arrays shared with the other private methods\n        solvedCols  = Math.min(rows, cols);\n        diagR       = new double[cols];\n        jacNorm     = new double[cols];\n        beta        = new double[cols];\n        permutation = new int[cols];\n        lmDir       = new double[cols];\n\n        // local point\n        double   delta   = 0;\n        double   xNorm   = 0;\n        double[] diag    = new double[cols];\n        double[] oldX    = new double[cols];\n        double[] oldRes  = new double[rows];\n        double[] work1   = new double[cols];\n        double[] work2   = new double[cols];\n        double[] work3   = new double[cols];\n\n        // evaluate the function at the starting point and calculate its norm\n        updateResidualsAndCost();\n\n        // outer loop\n        lmPar = 0;\n        boolean firstIteration = true;\n        while (true) {\n\n            incrementIterationsCounter();\n\n            // compute the Q.R. decomposition of the jacobian matrix\n            updateJacobian();\n            qrDecomposition();\n\n            // compute Qt.res\n            qTy(residuals);\n\n            // now we don't need Q anymore,\n            // so let jacobian contain the R matrix with its diagonal elements\n            for (int k = 0; k < solvedCols; ++k) {\n                int pk = permutation[k];\n                jacobian[k][pk] = diagR[pk];\n            }\n\n            if (firstIteration) {\n\n                // scale the point according to the norms of the columns\n                // of the initial jacobian\n                xNorm = 0;\n                for (int k = 0; k < cols; ++k) {\n                    double dk = jacNorm[k];\n                    if (dk == 0) {\n                        dk = 1.0;\n                    }\n                    double xk = dk * point[k];\n                    xNorm  += xk * xk;\n                    diag[k] = dk;\n                }\n                xNorm = Math.sqrt(xNorm);\n\n                // initialize the step bound delta\n                delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n            }\n\n            // check orthogonality between function vector and jacobian columns\n            double maxCosine = 0;\n            if (cost != 0) {\n                for (int j = 0; j < solvedCols; ++j) {\n                    int    pj = permutation[j];\n                    double s  = jacNorm[pj];\n                    if (s != 0) {\n                        double sum = 0;\n                        for (int i = 0; i <= j; ++i) {\n                            sum += jacobian[i][pj] * residuals[i];\n                        }\n                        maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n                    }\n                }\n            }\n            if (maxCosine <= orthoTolerance) {\n                // convergence has been reached\n                return new VectorialPointValuePair(point, objective);\n            }\n\n            // rescale if necessary\n            for (int j = 0; j < cols; ++j) {\n                diag[j] = Math.max(diag[j], jacNorm[j]);\n            }\n\n            // inner loop\n            for (double ratio = 0; ratio < 1.0e-4;) {\n\n                // save the state\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    oldX[pj] = point[pj];\n                }\n                double previousCost = cost;\n                double[] tmpVec = residuals;\n                residuals = oldRes;\n                oldRes    = tmpVec;\n\n                // determine the Levenberg-Marquardt parameter\n                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n\n                // compute the new point and the norm of the evolution direction\n                double lmNorm = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    lmDir[pj] = -lmDir[pj];\n                    point[pj] = oldX[pj] + lmDir[pj];\n                    double s = diag[pj] * lmDir[pj];\n                    lmNorm  += s * s;\n                }\n                lmNorm = Math.sqrt(lmNorm);\n\n                // on the first iteration, adjust the initial step bound.\n                if (firstIteration) {\n                    delta = Math.min(delta, lmNorm);\n                }\n\n                // evaluate the function at x + p and calculate its norm\n                updateResidualsAndCost();\n\n                // compute the scaled actual reduction\n                double actRed = -1.0;\n                if (0.1 * cost < previousCost) {\n                    double r = cost / previousCost;\n                    actRed = 1.0 - r * r;\n                }\n\n                // compute the scaled predicted reduction\n                // and the scaled directional derivative\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    double dirJ = lmDir[pj];\n                    work1[j] = 0;\n                    for (int i = 0; i <= j; ++i) {\n                        work1[i] += jacobian[i][pj] * dirJ;\n                    }\n                }\n                double coeff1 = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    coeff1 += work1[j] * work1[j];\n                }\n                double pc2 = previousCost * previousCost;\n                coeff1 = coeff1 / pc2;\n                double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n                double preRed = coeff1 + 2 * coeff2;\n                double dirDer = -(coeff1 + coeff2);\n\n                // ratio of the actual to the predicted reduction\n                ratio = (preRed == 0) ? 0 : (actRed / preRed);\n\n                // update the step bound\n                if (ratio <= 0.25) {\n                    double tmp =\n                        (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n                    if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {\n                        tmp = 0.1;\n                    }\n                    delta = tmp * Math.min(delta, 10.0 * lmNorm);\n                    lmPar /= tmp;\n                } else if ((lmPar == 0) || (ratio >= 0.75)) {\n                    delta = 2 * lmNorm;\n                    lmPar *= 0.5;\n                }\n\n                // test for successful iteration.\n                if (ratio >= 1.0e-4) {\n                    // successful iteration, update the norm\n                    firstIteration = false;\n                    xNorm = 0;\n                    for (int k = 0; k < cols; ++k) {\n                        double xK = diag[k] * point[k];\n                        xNorm    += xK * xK;\n                    }\n                    xNorm = Math.sqrt(xNorm);\n                } else {\n                    // failed iteration, reset the previous values\n                    cost = previousCost;\n                    for (int j = 0; j < solvedCols; ++j) {\n                        int pj = permutation[j];\n                        point[pj] = oldX[pj];\n                    }\n                    tmpVec    = residuals;\n                    residuals = oldRes;\n                    oldRes    = tmpVec;\n                }\n\n                // tests for convergence.\n                if (((Math.abs(actRed) <= costRelativeTolerance * previousCost) &&\n                     (preRed <= costRelativeTolerance * previousCost) &&\n                     (ratio <= 2.0)) ||\n                    (delta <= parRelativeTolerance * xNorm)) {\n                    return new VectorialPointValuePair(point, objective);\n                }\n\n                // tests for termination and stringent tolerances\n                // (2.2204e-16 is the machine epsilon for IEEE754)\n                if ((Math.abs(actRed) <= 2.2204e-16 * previousCost) && \n                    (preRed <= 2.2204e-16 * previousCost) && \n                    (ratio <= 2.0)) {\n                    throw new OptimizationException(\"cost relative tolerance is too small ({0}),\" +\n                            \" no further reduction in the\" +\n                            \" sum of squares is possible\",\n                            costRelativeTolerance);\n                } else if (delta <= 2.2204e-16 * xNorm) {\n                    throw new OptimizationException(\"parameters relative tolerance is too small\" +\n                            \" ({0}), no further improvement in\" +\n                            \" the approximate solution is possible\",\n                            parRelativeTolerance);\n                } else if (maxCosine <= 2.2204e-16)  {\n                    throw new OptimizationException(\"orthogonality tolerance is too small ({0}),\" +\n                            \" solution is orthogonal to the jacobian\",\n                            orthoTolerance);\n                }\n\n            }\n\n        }\n\n    }\n"
                        ],
                        "evaluation_done": true
                    }
                }
            }
        ],
        "trigger_test": {
            "org.apache.commons.math.optimization.general.MinpackTest::testMinpackJennrichSampson": {
                "path": "src/test/java/org/apache/commons/math/optimization/general/MinpackTest.java",
                "function_name": "testMinpackJennrichSampson",
                "src": "  public void testMinpackJennrichSampson() {\n    minpackTest(new JennrichSampsonFunction(10, new double[] { 0.3, 0.4 },\n                                            64.5856498144943, 11.1517793413499,\n                                            new double[] {\n                                             0.2578330049, 0.257829976764542\n                                            }), false);\n  }",
                "error_msg": "junit.framework.AssertionFailedError: expected:<0.2578330049> but was:<0.257819926636807>\n\tat junit.framework.Assert.fail(Assert.java:57)\n\tat junit.framework.Assert.failNotEquals(Assert.java:329)\n\tat junit.framework.Assert.assertEquals(Assert.java:120)\n\tat junit.framework.Assert.assertEquals(Assert.java:129)\n\tat junit.framework.TestCase.assertEquals(TestCase.java:288)\n\tat org.apache.commons.math.optimization.general.MinpackTest$MinpackFunction.checkTheoreticalMinParams(MinpackTest.java:575)\n\tat org.apache.commons.math.optimization.general.MinpackTest.minpackTest(MinpackTest.java:503)\n\tat org.apache.commons.math.optimization.general.MinpackTest.testMinpackJennrichSampson(MinpackTest.java:325)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat junit.framework.TestCase.runTest(TestCase.java:176)\n\tat junit.framework.TestCase.runBare(TestCase.java:141)\n\tat junit.framework.TestResult$1.protect(TestResult.java:122)\n\tat junit.framework.TestResult.runProtected(TestResult.java:142)\n\tat junit.framework.TestResult.run(TestResult.java:125)\n\tat junit.framework.TestCase.run(TestCase.java:129)\n\tat junit.framework.TestSuite.runTest(TestSuite.java:255)\n\tat junit.framework.TestSuite.run(TestSuite.java:250)\n\tat org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:520)\n\tat org.apache.tools.ant.taskdefs.optional.junit.JUnitTask.executeInVM(JUnitTask.java:1484)\n\tat org.apache.tools.ant.taskdefs.optional.junit.JUnitTask.execute(JUnitTask.java:872)\n\tat org.apache.tools.ant.taskdefs.optional.junit.JUnitTask.executeOrQueue(JUnitTask.java:1972)\n\tat org.apache.tools.ant.taskdefs.optional.junit.JUnitTask.execute1(JUnitTask.java:824)\n\tat org.apache.tools.ant.taskdefs.optional.junit.JUnitTask.execute(JUnitTask.java:2277)\n\tat org.apache.tools.ant.UnknownElement.execute(UnknownElement.java:291)\n\tat sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.tools.ant.dispatch.DispatchUtils.execute(DispatchUtils.java:106)\n\tat org.apache.tools.ant.Task.perform(Task.java:348)\n\tat org.apache.tools.ant.Target.execute(Target.java:392)\n\tat org.apache.tools.ant.Target.performTasks(Target.java:413)\n\tat org.apache.tools.ant.Project.executeSortedTargets(Project.java:1399)\n\tat org.apache.tools.ant.Project.executeTarget(Project.java:1368)\n\tat org.apache.tools.ant.helper.DefaultExecutor.executeTargets(DefaultExecutor.java:41)\n\tat org.apache.tools.ant.Project.executeTargets(Project.java:1251)\n\tat org.apache.tools.ant.Main.runBuild(Main.java:811)\n\tat org.apache.tools.ant.Main.startAnt(Main.java:217)\n\tat org.apache.tools.ant.launch.Launcher.run(Launcher.java:280)\n\tat org.apache.tools.ant.launch.Launcher.main(Launcher.java:109)",
                "clean_error_msg": "junit.framework.AssertionFailedError: expected:<0.2578330049> but was:<0.257819926636807>\n\tat org.apache.commons.math.optimization.general.MinpackTest.minpackTest(MinpackTest.java:503)  function.checkTheoreticalMinParams(optimum);\n\tat org.apache.commons.math.optimization.general.MinpackTest.testMinpackJennrichSampson(MinpackTest.java:325)  minpackTest(new JennrichSampsonFunction(10, new double[] { 0.3, 0.4 },                                            64.5856498144943, 11.1517793413499,                                            new double[] {                                             0.2578330049, 0.257829976764542                                            }), false);"
            },
            "org.apache.commons.math.optimization.general.MinpackTest::testMinpackFreudensteinRoth": {
                "path": "src/test/java/org/apache/commons/math/optimization/general/MinpackTest.java",
                "function_name": "testMinpackFreudensteinRoth",
                "src": "  public void testMinpackFreudensteinRoth() {\n    minpackTest(new FreudensteinRothFunction(new double[] { 0.5, -2.0 },\n                                             20.0124960961895, 6.99887517584575,\n                                             new double[] {\n                                               11.4124844654993,\n                                               -0.896827913731509\n                                             }), false);\n    minpackTest(new FreudensteinRothFunction(new double[] { 5.0, -20.0 },\n                                             12432.833948863, 6.9988751744895,\n                                             new double[] {\n                                               11.4121122022341,\n                                               -0.8968550851268697\n                                             }), false);\n    minpackTest(new FreudensteinRothFunction(new double[] { 50.0, -200.0 },\n                                             11426454.595762, 6.99887517242903,\n                                             new double[] {\n                                               11.412069435091231,\n                                               -0.8968582807605691\n                                             }), false);\n  }",
                "error_msg": "junit.framework.AssertionFailedError: expected:<11.4121122022341> but was:<11.41300466147456>\n\tat junit.framework.Assert.fail(Assert.java:57)\n\tat junit.framework.Assert.failNotEquals(Assert.java:329)\n\tat junit.framework.Assert.assertEquals(Assert.java:120)\n\tat junit.framework.Assert.assertEquals(Assert.java:129)\n\tat junit.framework.TestCase.assertEquals(TestCase.java:288)\n\tat org.apache.commons.math.optimization.general.MinpackTest$MinpackFunction.checkTheoreticalMinParams(MinpackTest.java:575)\n\tat org.apache.commons.math.optimization.general.MinpackTest.minpackTest(MinpackTest.java:503)\n\tat org.apache.commons.math.optimization.general.MinpackTest.testMinpackFreudensteinRoth(MinpackTest.java:152)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat junit.framework.TestCase.runTest(TestCase.java:176)\n\tat junit.framework.TestCase.runBare(TestCase.java:141)\n\tat junit.framework.TestResult$1.protect(TestResult.java:122)\n\tat junit.framework.TestResult.runProtected(TestResult.java:142)\n\tat junit.framework.TestResult.run(TestResult.java:125)\n\tat junit.framework.TestCase.run(TestCase.java:129)\n\tat junit.framework.TestSuite.runTest(TestSuite.java:255)\n\tat junit.framework.TestSuite.run(TestSuite.java:250)\n\tat org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:520)\n\tat org.apache.tools.ant.taskdefs.optional.junit.JUnitTask.executeInVM(JUnitTask.java:1484)\n\tat org.apache.tools.ant.taskdefs.optional.junit.JUnitTask.execute(JUnitTask.java:872)\n\tat org.apache.tools.ant.taskdefs.optional.junit.JUnitTask.executeOrQueue(JUnitTask.java:1972)\n\tat org.apache.tools.ant.taskdefs.optional.junit.JUnitTask.execute1(JUnitTask.java:824)\n\tat org.apache.tools.ant.taskdefs.optional.junit.JUnitTask.execute(JUnitTask.java:2277)\n\tat org.apache.tools.ant.UnknownElement.execute(UnknownElement.java:291)\n\tat sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.tools.ant.dispatch.DispatchUtils.execute(DispatchUtils.java:106)\n\tat org.apache.tools.ant.Task.perform(Task.java:348)\n\tat org.apache.tools.ant.Target.execute(Target.java:392)\n\tat org.apache.tools.ant.Target.performTasks(Target.java:413)\n\tat org.apache.tools.ant.Project.executeSortedTargets(Project.java:1399)\n\tat org.apache.tools.ant.Project.executeTarget(Project.java:1368)\n\tat org.apache.tools.ant.helper.DefaultExecutor.executeTargets(DefaultExecutor.java:41)\n\tat org.apache.tools.ant.Project.executeTargets(Project.java:1251)\n\tat org.apache.tools.ant.Main.runBuild(Main.java:811)\n\tat org.apache.tools.ant.Main.startAnt(Main.java:217)\n\tat org.apache.tools.ant.launch.Launcher.run(Launcher.java:280)\n\tat org.apache.tools.ant.launch.Launcher.main(Launcher.java:109)",
                "clean_error_msg": "junit.framework.AssertionFailedError: expected:<11.4121122022341> but was:<11.41300466147456>\n\tat org.apache.commons.math.optimization.general.MinpackTest.minpackTest(MinpackTest.java:503)  function.checkTheoreticalMinParams(optimum);\n\tat org.apache.commons.math.optimization.general.MinpackTest.testMinpackFreudensteinRoth(MinpackTest.java:152)  minpackTest(new FreudensteinRothFunction(new double[] { 5.0, -20.0 },                                             12432.833948863, 6.9988751744895,                                             new double[] {                                               11.4121122022341,                                               -0.8968550851268697                                             }), false);"
            }
        },
        "evaluation_done": true
    }
}